\documentclass[acmsmall,anonymous,fleqn]{acmart}\settopmatter{printfolios=false,printccs=false,printacmref=false}

%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}

\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{OOPSLA}
\acmArticle{1}
\acmYear{2019}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\settopmatter{printfolios=true}
%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations

\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{lineno,hyperref,xcolor}
\usepackage{flushend}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{xypic}
\usepackage{semantic}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage[T1]{fontenc}

\setlist{leftmargin=6mm}
\newcounter{thc}
\newcounter{dfc}

\theoremstyle{plain}
\newtheorem{lem}[thc]{Lemma}
\newtheorem{theorem}[thc]{Theorem}

\theoremstyle{definition}
\newtheorem{axiom}[dfc]{Axiom}
\newtheorem{definition}[dfc]{Definition}

\title{Live coding environment for a data exploration language}
\author{Tomas Petricek}

\affiliation{
  \institution{University of Kent}
  \country{United Kingdom}
}
\email{tomas@tomasp.net}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}

\definecolor{cmtclr}{rgb}{0.0,0.6,0.0}
\definecolor{kvdclr}{rgb}{0.0,0.0,0.6}
\definecolor{idclr}{rgb}{0.3,0.3,0.3}
\definecolor{numclr}{rgb}{0.0,0.4,0.0}
\definecolor{strclr}{rgb}{0.4,0.4,0.0}
\definecolor{rstrclr}{rgb}{0.5,0.1,0.0}
\definecolor{prepclr}{rgb}{0.6,0.0,0.2}
\newcommand{\vect}[1]{\langl #1 \rangl}
\newcommand{\langl}{\begin{picture}(4.5,7)
\put(1.1,2.5){\rotatebox{60}{\line(1,0){5.5}}}
\put(1.1,2.5){\rotatebox{300}{\line(1,0){5.5}}}
\end{picture}}
\newcommand{\rangl}{\begin{picture}(4.5,7)
\put(.9,2.5){\rotatebox{120}{\line(1,0){5.5}}}
\put(.9,2.5){\rotatebox{240}{\line(1,0){5.5}}}
\end{picture}}
\newcommand{\ball}[1]{\FPeval{\result}{clip(201+#1)}\textnormal{\ding{\result}}}
\newcommand{\lsep}{\;\;|\;\;}
\newcommand{\num}[1]{\textcolor{numclr}{#1}}
\newcommand{\str}[1]{\textnormal{\textcolor{strclr}{\sffamily "#1"}}}
\newcommand{\rstr}[1]{\textnormal{\textcolor{rstrclr}{\sffamily "#1"}}}
\newcommand{\ident}[1]{\textnormal{\textcolor{idclr}{\sffamily #1}}}
\newcommand{\qident}[1]{\textnormal{\sffamily \textquotesingle #1\textquotesingle}}
\newcommand{\dom}{\ident{dom}}
\newcommand{\kvd}[1]{\textnormal{\textcolor{kvdclr}{\sffamily #1}}}

\newcommand{\bndclr}[1]{\textcolor{kvdclr}{#1}}
\newcommand{\bkndclr}[1]{\textcolor{prepclr}{#1}}
\newcommand{\blblclr}[1]{\textcolor{numclr}{#1}}
\newcommand{\bnd}[1]{\textnormal{\textcolor{kvdclr}{\sffamily #1}}}
\newcommand{\bknd}[1]{\textnormal{\textcolor{prepclr}{\sffamily #1}}}
\newcommand{\blbl}[1]{\textnormal{\textcolor{numclr}{\sffamily #1}}}
\newcommand{\narrow}[1]{\hspace{-0.6em}#1\hspace{-0.6em}}
\newcommand{\rname}[1]{{\sffamily\small(#1)}}
\newcommand{\ername}[1]{\vspace{0.75em}\rname{#1}\hspace{0.5em}}
\newcommand{\preview}[1]{\,\textnormal{\guillemotleft} #1\textnormal{\guillemotright}\,}

\begin{document}
\begin{abstract}

A growing amount of code is written to explore and analyze data, but the way data analysts
work with code differs from the way software engineers do. First, many data
scientists write code that introduces few or no abstractions. Second, data exploration is an
interactive process and it blurs the traditional distinction between development-time and run-time.
This poses an interesting challenge for programming language research, because it allows us to
revisit a number of traditional assumptions about programming languages and focus our attention
on a new kind of programming tools that data analysts need.

In this paper, we present \emph{data exploration calculus}, a formally tractable
language that captures the structure of simple data analyses as done, for example, by journalists
exploring open government data. We implement a programming environment for data exploration that
evaluates code instantaneously during editing and shows previews of the results,
while allowing the user to modify code in an unrestricted way in a text
editor. Supporting a text editor is tricky as any edit can change the structure
of code and fully recomputing program after every change would be too expensive.
We present a new technique that allows evaluating and type-checking code while it is
being written while reusing results of previous runs. We formalize the technique using the data
exploration calculus, prove that it is correct and specify when previous results are reused.
Finally, we also illustrate the practicality of our approach using empirical evaluation
and a case study.

As data analysis becomes ever more important use of programming, research on programming languages
and tools needs to consider new kinds of code that people need to write and new kinds of tools
that can support them. The present paper is one step in this important direction.
\end{abstract}
\maketitle

% ==================================================================================================

\section{Introduction}
\label{sec:intro}
One of the aspects that make spreadsheets easier to use than programming tools is their
liveness. When you change a value in a cell in Excel, the whole spreadsheet updates instantly
and you immediately see new results, without having to explicitly trigger re-computation
and without having to wait for an extensive period of time.

Increasing number of programming environments aim to provide the same live development experience
for standard programming languages, but doing this is not easy. Fully recomputing the whole program
after every keystroke is inefficient and calculating how a change in the source code changes the
result is extremely hard when the text editor allows arbitrary changes.
Consider the following snippet that gets the release years of 10 most expensive movies from a
data set \ident{movies}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{top} =\ident{movies}.\ident{sortBy}(\lambda x \rightarrow x.\ident{getBudget}())\\
\qquad .\ident{take}(\num{10}).\ident{map}(\lambda x \rightarrow x.\ident{getReleased()}.\ident{format}(\str{yyyy}))\\
\end{array}
\end{equation*}
%
A live coding environment computes and shows the list of years, but then the programmer modifies the code by
making the constant $\num{10}$ a variable and changing the date format to see the full date:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{count} = \num{10}\\
\kvd{let}~\ident{top} = \ident{movies}.\ident{sortBy}(\lambda x \rightarrow x.\ident{getBudget}())\\
\qquad .\ident{take}(\ident{count}).\ident{map}(\lambda x \rightarrow x.\ident{getReleased()}.\ident{format}(\str{dd-mm-yyyy}))\\
\end{array}
\end{equation*}
%
Ideally, the live coding environment should understand the change, reuse a cached result of the
first two transformations (sorting and taking first 10 elements) and only evaluate the
\ident{map} operation to differently format the release dates of already computed top 10 movies.
We present such a live coding environment, describe it formally and empirically evaluate it.
We discuss related work in Section~\ref{sec:future}, but we review the most important directions
next, in order to situate our contributions.

\subsection{Related work}
We focus on simple data exploration as done, for example, by journalists \cite{ddj}
and we aim to bring the experience of using transparent and reproducible programming tools
closer to that of using spreadsheets. When a user edits a cell in a spreadsheet, the results
automatically update. Recomputation in spreadsheets is well-studied,~e.g. by \citet{spreadsheet},
but it is simpler than in our case, because editing is limited to individual cells.

Many visual data exploration tools support interactivity \cite{control,tableau,vizdom} and some,
can even export the workflow as a script \cite{wrangler}, but data anlysts who prefer working with
code typically resort to notebook systems such as Jupyter or R Markdown \cite{jupyter,rmarkdown}.
Those are text-based, but have a limited model of recomputation. Users have to structure code in
cells and manually reevaluate cells after a change. Those systems also do not track
dependencies between cells, which can lead to inconsistencies; an issue that has been addressed
by e.g.~\citet{dataflow} or \citet{wrattler}.

We aim to keep the transparency and reproducibility of notebooks, but add a correct and
efficient instantaneous evaluation mechanism. Existing text-based editors that provide instant,
such as Lighttable \cite{lighttable} and Chrome DevTools, often work only in certain
situations or require full recomputation. A more principled approach has been used by
systems based on structured editing \cite{livenut,lamdu}, which benefit from the fact that code
can only be modified via known operations with known effect on the computation graph
(``extract variable'' has no effect on the result; ``change constant value''
forces recomputation of subsequent code). However, we aim to cater for the many users who
prefer to edit programs as free-form text.

The technical aspects of our technique for providing instantaneous feedback
are related to the work on incremental computation \cite{selfadjusting,incremental}. This focuses
on cases where \emph{data} changes but program stays the same, while our focus is on cases where
\emph{program} changes but data stays. Yet, the technical aspects are related and,
as noted in Section~\ref{sec:future}, language that supports incremental computation could be used
to implement the kind of system presented in this paper.

\subsection{Contributions}
We present the design and implementation of a live coding environment for a data exploration
language that provides a correct and efficient instantaneous feedback, yet, is integrated into an
ordinary text editor. Our most important contributions are:

\begin{itemize}[itemsep=3pt]
\item We introduce \emph{data exploration calculus} (Section~\ref{sec:calculus}), a small formally
  tractable programming language for data exploration. The language is motivated by our review
  of how data analysts work (Section~\ref{sec:background}) and captures the idea that scripts are
  often lists of commands with few or no abstractions with most logic provided by external libraries.

\item Implementing a live coding environment requires a different way of thinking than the one
  presented in classic compiler literature. We capture the essence of the new perspective
  (Section~\ref{sec:formal}) and use it to build our \emph{live preview} mechanism
  (Section~\ref{sec:previews}) evaluates code instantaneously during editing.

\item We prove that our live preview mechanism is correct (Section~\ref{sec:evaluation-correctness}) and that
  it reuses previously evaluated values when possible (Section~\ref{sec:evaluation-reuse}). We
  illustrate the practicality of the mechanism using an empirical evaluation
  (Section~\ref{sec:evaluation-empirical}) and a case study (Section~\ref{sec:case}).

\item We extend our core environment in two ways, First, we add instantaneous type checker
  that relies on the same core infrastructure as live previews and enables richer user experience
  through \emph{type providers} (Section~\ref{sec:types}). Second, we add an abstraction mechanism
  that preserves the live coding experience (Section~\ref{sec:design}).
\end{itemize}

% ==================================================================================================

\begin{figure}[b]
\includegraphics[scale=0.5]{notebook.png}
\caption{An excerpt from a Jupyter notebook by Financial Times reporters, which loads trade
  data from the UN trade database (stored in a local file) and adds ISO country codes (from
  an Excel spreadsheet).}
\label{fig:ft-uncomtrade}
\end{figure}

% --------------------------------------------------------------------------------------------------

\section{Understanding how data scientists work}
\label{sec:background}

Data scientists often use general-purpose programming languages such as Python, but the kind of
code they write and the way they interact with the system is very different from how software
engineers work \cite{workflow}. This paper focuses on simple data wrangling and data exploration as done, for
example, by journalists analysing government datasets. This section illustrates how such data
analyses look and provides a justification for the design of our data exploration calculus.

% --------------------------------------------------------------------------------------------------

\subsection{Data wrangling in Jupyter}
\label{sec:background-jupyter}

Data analysts increasingly use notebook systems such as Jupyter, which
make it possible to combine text, equations and code with results of running the code such as tables
or visualizations. Notebooks blur the distinction between development and execution.
Data analysts write small snippets of code, run them to see results immediately and then revise
them.

Jupyter notebooks are used by a variety of users ranging from scientists who implement complex
models of physical systems to journalists who load data, perform simple aggregations and create visualizations. Our
initial focus is on simple use cases, such as those of journalists. Tooling that makes notebook
systems more interactive and spreadsheet-like can encourage users to choose programming tools
over spreadsheets and produce reproducible and transparent data analyses.

As an example, the anlysis done by the Financial Times for an article on plastic waste
\cite{ftnotebooks,ftarticle} joins datasets from Eurostat, UN Comtrade and more, aggregates the data and
builds a visualization comparing waste flows in 2017 and 2018. Figure~\ref{fig:ft-uncomtrade} shows
an extract from one notebook from the data analysis. The code has a number of remarkable properties:
%
\begin{itemize}[itemsep=3pt]
\item There is no abstraction. The analysis uses lambda functions as arguments to library calls,
  but it does not define any top-level functions. Parameterization is done by defining a list of
  inputs and then having a for loop, or by defining a top-level variable and setting its value.
  In our example, \ident{material} is set to \str{plastics} and a comment lists other options.
  This lets the analyst easily see and check the results of intermediate steps of the analysis.

\item The code relies on external libraries. Our example uses Pandas \cite{pandas},
  which provides opreations for data wrangling such as \ident{merge} to join datasets
  or \ident{drop\_duplicates} to delete rows with duplicate column values. Those libraries are
  external to the data analysis and may even be implemented in other languages -- many Python
  libraries rely on C++.

\item The code is structured as a sequence of commands. Some commands define a variable, either by
  loading data, or by transforming data loaded previously. Even in Python, data is often treated
  as immutable. Other commands produce an output that is displayed in the notebook.

\item There are many corner cases, such as the fact that the \ident{keep\_default\_na} parameter
  needs to be set to handle Namibia correctly. These are discovered interactively by writing and
  running a code snippet and examining the output, so providing a rapid feedback is essential.
\end{itemize}

\noindent
Many Jupyter notebooks are more complex than the example discussed here. They might define
helper functions or even structure code using object-oriented programming. However, this paper
is motivated by our conviction that simple data analyses such as the one discussed here are frequent
enough to pose an interesting and important domain for programming tools research.

% --------------------------------------------------------------------------------------------------

\begin{figure}[b]
  \centering
  \subcaptionbox{
    \raggedright\footnotesize The Gamma script to aggregate Olympic medals. The analyst selects
      Rio 2016 games and counts the number of distinct events per athlete. After typing `.',
      a type provider offers further aggregation operations.
    \label{fig:gamma-dot}
  }{\includegraphics[scale=0.26]{gamma1.png}}
  \subcaptionbox{
    \raggedright\footnotesize Live preview in The Gamma programming environment developed based on
      the theory presented in this paper. The table is produced as
      the data anlyst types and updates on-the-fly to show result at the current cursor position.
    \label{fig:gamma-preview}
  }{\includegraphics[scale=0.26]{gamma2.png}}
  \caption{\small Data exploration in The Gamma -- using a type provider (left) and with a live
    preview (right).}
  \label{first-figure-with-subfigures}
\end{figure}

\subsection{Dot-driven data exploration in The Gamma}
\label{sec:background-gamma}

Data exploration of the kind discussed in the previous section has been the motivation for a
recent work by \citet{gamma} that develops a small scripting language called The Gamma. The language
follows the structure discussed above. A script is a sequence of commands that can either define a
variable or produce an output. The language does not support top-level function declarations
and lambda functions can be used only as method arguments.

Given the limited expressiveness of The Gamma, libraries are implemented in other languages,
such as JavaScript. The Gamma also supports type providers \cite{providers-fsharp},
which can be used to generate types, on the fly, for accessing and exploring external data sources.
Type providers provide object types with members and The Gamma makes using those convenient by
providing auto-complete when the user types the dot symbol (`.') to access a member.

As illustrated by \citet{gamma}, the combination of type providers and auto-complete on~`.' makes it
possible to complete a large number of data exploration tasks through a very simple interaction of
selecting operations from a list. An example in Figure~\ref{fig:gamma-dot} summarizes data on
Olympic medals using a type provider. The names of identifiers such as \qident{sum Bronze} do not have
any special meaning. They are merely members generated by the type provider, based on information
about the data source. The type provider used in this example generates an object with members for
different data transformations, such as \qident{group data}, which return furhter objects with
members for specifying transformation parameters, such as selecting the grouping key using
\qident{by Athlete}.

The Gamma language is richer, but the example in Figure~\ref{fig:gamma-dot} shows that non-trivial
data exploration can be done using a very simple language. The assumptions about strucutre of
code that are explicit in The Gamma are implicitly present in Python and R data analyses
produced by journalists, economists and other users with other than programming background.
When we refer to The Gamma in this paper, readers not familiar with it can assume that we focus
on a subset of Python.

% --------------------------------------------------------------------------------------------------

\subsection{Live coding for data exploration}

The practical implementation work that complements the theory presented in this paper implements a live
coding environment for The Gamma and is discussed in Section~\ref{sec:case} in detail. Earlier work by
\citet{gamma} discussed The Gamma language and the type provider mechanism, but the implementation
provided only a standard text editor with auto-completion. Our work brings the experience of using
The Gamma closer to that of spreadsheets by developing an editor that evaluates scripts
instantaneously in background and displays the results as \emph{live previews}.

An example of a live preview is shown in Figure~\ref{fig:gamma-preview}. As noted earlier, The
Gamma program consits of a list of commands which are either expressions or let bindings. Our
editor displays a live preview below the command that the user is currently editing. The preview
shows the result of evaluating the expression or the value assigned to a bound variable. When the
user changes the code, the preview is updated automatically, without any additional interaction
with the user.

There is a number of guiding principles that our work follows. First, we allow the analyst
to edit code in an unrestricted form in a text editor. Although structured editors provide an
appearling alternative and make recomputation easier, we prefer the transparency
and openness of plain text. Second, we focus on the scenario when code changes, but input
does not. Rapid feedback allows the analyst to quickly adapt code to correctly handle
corner cases that typical analysis involves. In contrast to work on incremental computation,
we do not consider the case when data changes, although supporting interactive data exploration
of streaming data is an interesting future direction.

% ==================================================================================================

\section{Data exploration calculus}
\label{sec:calculus}

The \emph{data exploration calculus} is a small, formally tractable language for data exploration.
The calculus is not Turing-complete and it can only be used together with external libraries that
define what objects are available and what the behaviour of their members is. This is
sufficient to capture the simple data analyses discussed in Section~\ref{sec:background}. We
define the caluclus in this section and then use it as the basis for discussing our live preview
mechanism in Section~\ref{sec:formal}.

We initially present the data exploration calculus without a static type system. The live preview
mechanism can be discussed equally well without types. We consider type checking later in
Section~\ref{sec:types} as the mechanism that is used for live previews can also be
used for incremental type-checking.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\raggedright
\hspace{1.5em}{\small\sffamily Programs, commands, terms, expressions and values}
\begin{equation*}
\begin{array}{lcl}
p &\narrow{=}& c_1; \ldots; c_n\\
c &\narrow{=}& \kvd{let}~x = t \lsep t\\
\end{array}
\qquad
\begin{array}{lcl}
t &\narrow{=}& o \lsep x \\
  &\narrow{|}& t.m(e, \ldots, e)
\end{array}
\qquad
\begin{array}{lcl}
e &\narrow{=}& t \lsep \lambda x\rightarrow e\\
v &\narrow{=}& o \lsep \lambda x\rightarrow e\\
\end{array}
\end{equation*}

\vspace{0.5em}
\hspace{1.5em}{\small\sffamily Evaluation contexts of expressions}
\begin{equation*}
\begin{array}{lcl}
C_e[-] &=& C_e[-].m(e_1, \ldots, e_n) ~\lsep~ o.m(v_1, \ldots, v_{m}, C_e[-], e_1,\ldots , e_n) ~\lsep~ -\\
C_c[-] &=& \kvd{let}~x = C_e[-] ~\lsep~ C_e[-]\\
C_p[-] &=& o_1;\; \ldots;\; o_{k};\; C_c[-];\; c_{1};\; \ldots;\; c_n\\
\end{array}
\end{equation*}

\vspace{0.5em}
\hspace{1.5em}{\small\sffamily Let elimination and member reduction}
\begin{equation*}
\begin{array}{ll}
\hspace{-0.5em}\begin{array}{l}
o_1;\; \ldots;\; o_{k};\; \kvd{let}~x=o;\; c_{1};\; \ldots; c_n \rightsquigarrow\\
\qquad  o_1;\; \ldots;\; o_{k};\; o; c_{1}[x\leftarrow o];\; \ldots; c_n[x\leftarrow o]\end{array} &
\quad\text{\rname{let}}\\[1.2em]
{o.m(v_1, \ldots, v_n) \rightsquigarrow_\epsilon o'}\implies
  {C_p[o.m(v_1, \ldots, v_n)] \rightsquigarrow C_p[o']} &
\quad\text{\rname{external}}
\end{array}
\end{equation*}

\vspace{-0.5em}
\caption{Syntax, contexts and reduction rules of the data exploration calculus}
\label{fig:dec-calculus}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Language syntax}
The calculus combines object-oriented features such as member access with functional features
including lambda functions. The syntax is defined in Figure~\ref{fig:dec-calculus}. Object values
$o$ are defined by external libraries that are used in conjunction with the core calculus.

A program $p$ in the data exploration calculus consists of a sequence of commands $c$. A command
can be either a let binding or a term. Let bindings define variables $x$ that can be used in
subsequent commands. The calculus supports lambda functions, but they
can only appear as arguments in method calls. A term $t$ can be a value, variable or a
member access, while an expression $e$, which can appear as an argument in member access,
can be a lambda function or a term.\footnote{Similar but weaker restrictions on the use of lambda
functions exist in other languages. For example, in order to guide type inference, lambda functions
in C\# can appear as either method arguments or assigned to an explicitly typed variable, but they
cannot be assigned to an implicitly typed variable.}

\subsection{Operational semantics}
\label{sec:calculus-semantics}

The data exploration calculus is a call-by-value language. We model the evaluation as a small-step
reduction $\rightsquigarrow$. Fully evaluating a program results in an irreducible sequence of
objects $o_1;\; \ldots;\; o_n$ (one object for each command, including let bindings) which can be
displayed as intermediate results of the data analysis. The operational semantics is parameterized
by a relation $\rightsquigarrow_\epsilon$ that models the functionality of the external libraries
used with the calculus and defines reduction rules for member accesses. The relation has the
following form:
%
\begin{equation*}
o_1.m(v_1, \ldots, v_n) \rightsquigarrow_\epsilon o_2
\end{equation*}
%
The operation is invoked on an object and takes values (objects or function values) as arguments.
It always results in an opaque object.
Figure~\ref{fig:dec-calculus} defines the reduction rules in terms of $\rightsquigarrow_\epsilon$
and evaluation contexts; $C_e$ specifies left-to-right evaluation of arguments of a method call,
$C_c$ specifies evluation of a command and $C_p$ defines top-to-bottom evaluation of a program.
The rule \rname{external} applies reductions provided by an external library in a
call-by-value order and \rname{let} substitutes a value of an evaluated variable in
all subsequent commands. Note that \rname{let} leaves the value of the variable
in the resulting list of commands.

\subsection{Properties}
The data exploration calculus is a very simple language and it has a number of desirable
properties. However, some of those require that the relation $\rightsquigarrow_\epsilon$, which
defines evaluation for external libraries, satisfies a number of conditions. Our main motivation
is to capture properties that allow us to prove that our method of evaluating live previews,
discussed in Section~\ref{sec:evaluation-correctness}, is correct.

\begin{definition}[Further reductions]
\label{def:further-red}
We define two additional reduction relations:
\begin{itemize}
\item[-] We write $\rightsquigarrow^{*}$ for the reflexive, transitive closure of $\rightsquigarrow$
\item[-] We write $\rightsquigarrow_\ident{let}$ for a call-by-name let binding elimination\\
  $c_1;\; \ldots;\; c_{k-1};\; \kvd{let}~x=t;\; c_{k+1};\; \ldots; c_n ~\rightsquigarrow_\ident{let}~
  c_1;\; \ldots;\; c_{k-1};\; t; c_{k+1}[x\leftarrow t];\; \ldots; c_n[x\leftarrow t]$
\end{itemize}
\end{definition}

\noindent
We say that two expressions
$e$ and $e'$ are observationally equivalent if, for any context $C$, the expressions $C[e]$ and
$C[e']$ reduce to the same value. Lambda functions $\lambda x\!\rightarrow\!2$ and
$\lambda x\!\rightarrow\!1\!+\!1$ are not equal, but they are observationally equivalent.
We require that external libraries satisfy two conditions. First, when a method is called with
observationally equivalent values as arguments, it should return the same value. Second, the
evaluation of $o.m(v_1,\ldots,v_n)$ should be defined for all $o, i$ and $v_i$. The external
library will typically satisfy this by defining an error object and reducing all invalid calls
to the error object, following the standard method of \citet{gowrong}.

\begin{definition}[External library]
\label{def:external}
An external library consists of a set of objects $O$ and a reduction relation
$\rightsquigarrow_\epsilon$ that satsifies the following two properties:
\begin{itemize}
\item[-] \emph{Completeness.} For all $o, m, i$ and all $v_1, \ldots, v_i$, there exists $o'$ such
  that $o.m(v_1, \ldots, v_i) \rightsquigarrow_\epsilon o'$.
\vspace{0.5em}
\item[-] \emph{Compositionality.} For observationally equivalent arguments, the reduction returns
  the same object, i.e.~given $e_0, e_1, \ldots, e_n$ and $e'_0, e'_1, \ldots, e'_n$ and $m$ such that
  $e_0.m(e_1, \ldots, e_n) \rightsquigarrow^{*} o$ and $e'_0.m(e'_1, \ldots, e'_n) \rightsquigarrow^{*} o'$ then
  if for any contexts $C_0, C_1, \ldots, C_n$ it holds that if $C_i[e_i] \rightsquigarrow^{*} o_i$ and
  $C_i[e'_i] \rightsquigarrow^{*} o_i$ for some $o_i$ then $o = o'$.
\end{itemize}
\end{definition}

\noindent
The compositionality condition is essential for proving the correctness of our live preview mechanism.
Completeness allows us to prove normalization, i.e.~all programs reduce to
a value -- although the resulting value may be an error value provided by the external library.

\begin{theorem}[Normalization]
\label{thm:normalization}
For all $p$, there exists $n$ and $o_1, \ldots, o_n$ such that $p\rightsquigarrow^{*} o_1;\ldots;o_n$.
\end{theorem}
\begin{proof}
A program that is not a sequence of values can be reduced and reduction decreases the size of the
program. See Appendix~\ref{sec:app-normalization} for more detail.
\end{proof}

\noindent
Although the reduction rules \rname{let} and \rname{external} of the data exploration calculus
define an evaluation in a call-by-value order, eliminating let bindings in a call-by-name way
using the $\rightsquigarrow_\ident{let}$ reduction does not affect the result. This
simplifies our later proof of live preview correctness in Section~\ref{sec:evaluation-correctness}.

\begin{lem}[Let elimination for a program]
\label{thm:let-lang-elimination}
Given any program $p$ such that $p \rightsquigarrow^{*} o_1;\ldots;o_n$ for some $n$ and $o_1, \ldots, o_n$
then if $p \rightsquigarrow_\ident{let} p'$ for some $p'$ then also $p' \rightsquigarrow^{*} o_1;\ldots;o_n$.
\end{lem}
\begin{proof}
The elimination of let binding transforms a program $c_1;\; \ldots;\; c_{k-1};\; \kvd{let}~x=t;\; c_{k+1};\; \ldots; c_n$
to a program $c_1;\; \ldots;\; c_{k-1};\; t; c_{k+1}[x\leftarrow t];\; \ldots; c_n[x\leftarrow t]$.
The reduction steps for the new program can be constructed using the steps of $p \rightsquigarrow^{*} o_1;\ldots;o_n$.
The new command $t$ reduces to an object $o$ using the same steps as the original term $t$
in $\kvd{let}~x=t$ but with context $C_c = -$ rather than $C_c = \kvd{let}~x=-$; the terms $t$
introduced by substitution also reduce using the same steps as before, but using
contexts in which the variable $x$ originally appeared.
\end{proof}

\newpage

% ==================================================================================================

\section{Formalising live coding environment}
\label{sec:formal}

A naive way of providing live previews during code editing would be to re-evaluate the code
after each change. This would be wasteful -- for example, when writing
code, most changes are additive and the preview can be updated by evaluating just the newly added
code. In this section, we develop foundations for an efficient way of displaying live previews
for the data exploration calculus.

% --------------------------------------------------------------------------------------------------

\subsection{Maintaining dependency graph}
\label{sec:formal-deps}

The key idea behind our method is to maintain a dependency graph \cite{dependencies} with
nodes representing individual operations of the computation that can be (partially) evaluated
to obtain a preview. Each time the program text is modified, we parse it afresh (using an
error-recovering parser) and bind the abstract syntax tree to the dependency graph.
When binding a new expression to the graph, we reuse previously created nodes as long as
they have the same dependencies. For expressions that have a new structure, we create new nodes.

The nodes of the graph serve as unique keys into a lookup table with previously
evaluated parts of the program. When a preview is requested for an expression, we use the graph
node bound to the expression to find a preview. If a preview has not been evaluated, we force
the evaluation of all dependencies in the graph and then evaluate the operation represented by
the current node.

% --------------------------------------------------------------------------------------------------

\begin{figure}[b]
\centering
\subcaptionbox{
  \raggedright\small
  Graph constructed from the following initial expression:
  $\kvd{let}~x = \num{15}~\kvd{in}~\ident{data.skip}(\num{10}).\ident{take}(x)$
  \label{fig:dep-graph-a}
}{
  $\xymatrix{
  \bnd{val}(\num{10}) & \bnd{val}(\num{15})\\
  \bnd{mem}(\ident{skip},s_0)\ar[d]_{\blbl{arg}(0)} \ar[u]^{\blbl{arg}(1)} &
  \bnd{mem}(\ident{take},s_1)\ar[l]_{\blbl{arg}(0)} \ar[u]_{\blbl{arg}(1)}\\
  \bnd{var}(\ident{data})
  }\qquad$
}
\hspace{1em}
\subcaptionbox{
  \raggedright\small
  Updated graph after changing $x$ to $10$:
  $\kvd{let}~x = \num{10}~\kvd{in}~\ident{data.skip}(\num{10}).\ident{take}(x)$
  \label{fig:dep-graph-b}
}{
  $\xymatrix{
  \bnd{val}(\num{10})&\\
  \bnd{mem}(\ident{skip}, s_0)\ar[d]_{\blbl{arg}(0)} \ar[u]^{\blbl{arg}(1)} &
  \bnd{mem}(\ident{take}, s_2)\ar[l]_{\blbl{arg}(0)} \ar@/_/[lu]_{\blbl{arg}(1)}\\
  \bnd{var}(\ident{data})
}\qquad$
}
\caption{Dependency graphs formed by two steps of the live programming process. }
\label{fig:dep-graph}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsubsection{Elements of the graph}
The nodes of the graph represent individual operations of the computation. In our design, the nodes
are used as cache keys, so we attach a unique symbol $s$ to some of the nodes. That way, we can
create two unique nodes representing, for example, access to a member named \ident{take} which
differ in their dependencies.

Furthermore, the graph edges are labeled with labels indicating the kind of dependency. For
a method call, the labels are ``first argument'', ``second argument'' and so on. Writing
$s$ for symbols and $i$ for integers, nodes (vertices) $\bndclr{v}$ and edge labels $\blblclr{l}$
are defined as:
%
\begin{equation*}
\begin{array}{rcll}
\bndclr{v}&=&\bnd{val}(o) \lsep \bnd{var}(x)\lsep \bnd{mem}(m, s)\lsep \bnd{fun}(x, s)&(\textit{Vertices})\\
\blblclr{l}&=&\blbl{body} \lsep \blbl{arg}(i)&(\textit{Edge labels})\\
\end{array}
\end{equation*}
%
The \bnd{val} node represents a primitive value and contains the object itself. Two occurrences
of $\num{10}$ in the source code will be represented by the same node. Member access \bnd{mem}
contains the member name, together with a unique symbol $s$ -- two member access nodes with
different dependencies will contain a different symbol. Dependencies of member access are labeled
with \blbl{arg} indicating the index of the argument (the instance has index $0$ and arguments
start with $1$). Finally, nodes \bnd{fun} and \bnd{var} represent function values and variables
bound by $\lambda$ abstraction. For simplicity, we use variable names rather than de Bruijn
indices and so renaming a bound variable forces recomputation.

% --------------------------------------------------------------------------------------------------

\subsubsection{Example graph}
Figure~\ref{fig:dep-graph} illustrates how we construct and update the
dependency graph. Node representing $\ident{take}(x)$ depends on the argument -- the
number $\num{15}$ -- and the instance, which is a node representing $\ident{skip}(\num{10})$.
This, in turn, depends on the instance \ident{data} and the number $\num{10}$. Note that variables
bound via \kvd{let} binding such as $x$ do not appear as $\bnd{var}$ nodes. The node using it
depends directly on the node representing the expression that is assigned to $x$.

After changing the value of $x$, we create a new graph. The dependencies of the node
$\bnd{mem}(\ident{skip}, s_0)$ are unchanged and so the symbol $s_0$ attached to the node remains
the same and previously computed previews can be reused. This part of the program is not recomputed.
The $\blbl{arg}(1)$ dependency of the \ident{take} call
changed and so we create a new node $\bnd{mem}(\ident{skip}, s_2)$ with a fresh symbol $s_2$.
The preview for this node is then computed as needed using the already known values of its
dependencies.

% --------------------------------------------------------------------------------------------------

\subsubsection{Reusing graph nodes}
The binding process takes an expression and constructs a dependency graph reusing existing nodes
when possible. For this, we use a lookup table of member access and function value nodes. The key
in the lookup table is formed by a node kind (for disambiguation) together with a list of
dependencies. A node kind is a member access containing the member name or a function containing
the bound variable name; a lookup table $\Delta$ then maps a node kind with a list of dependencies
to a cached node:
%
\begin{equation*}
\begin{array}{ll}
\bkndclr{k}~=~\bknd{fun}(x)~|~\bknd{mem}(m)&(\textit{Node kinds})\\[0.2em]
\Delta(\bkndclr{k}, [(\bndclr{v_1},\blblclr{l_1}), \ldots, (\bndclr{v_n},\blblclr{l_n})])  & (\textit{Lookup for a node})
\end{array}
\end{equation*}
%
The example on the second line looks for a node of a kind $\bkndclr{k}$ that has dependencies
$\bndclr{v_1}, \ldots, \bndclr{v_n}$ labeled with labels $\blblclr{l_1}, \ldots, \blblclr{l_n}$.
We write $\Delta(\bndclr{k}, l)\!\downarrow$ when a value for a given key is not defined.
For example, when creating the graph in Figure~\ref{fig:dep-graph-b},
we perform the following lookup for the \ident{skip} member access:
%
\[ \Delta(\bknd{mem}(\ident{skip}), [(\bnd{var}(\ident{data}),\blbl{arg}(0)), (\bnd{val}(\num{10}), \blbl{arg}(1))]) \]
%
The lookup returns the node $\bnd{mem}(\ident{skip}, s_0)$ known from the previous step. We then perform
the following lookup for the \ident{take} member access:
%
\[ \Delta(\bknd{mem}(\ident{take}), [(\bnd{mem}(\ident{skip}, s_0),\blbl{arg}(0)), (\bnd{val}(\num{10}), \blbl{arg}(1))]) \]
%
In the previous graph, the argument of \ident{take} was $\num{15}$ rather than $\num{10}$ and so
this lookup fails. We then construct a new node $\bnd{mem}(\ident{take}, s_2)$ using a fresh
symbol $s_2$.

% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
\begin{equation*}
\hspace{-3.5em}
\begin{array}{ll}
\ident{bind-expr}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n)) = \bndclr{v}, (\{\bndclr{v}\} \cup V_0 \cup \ldots \cup V_n, E \cup E_0 \cup \ldots \cup E_n) &(1)~~\\
\quad \textnormal{when}~\bndclr{v_i}, (V_i, E_i) = \ident{bind-expr}_{\Gamma, \Delta}(e_i)
~\textnormal{and}~\bndclr{v} = \Delta(\bknd{mem}(m),[(\bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v_n}, \blbl{arg}(n))])\\
\quad \textnormal{let}~E = \{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v}, \bndclr{v_n}, \blbl{arg}(n))\}
\\[1em]
\ident{bind-expr}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n)) = \bndclr{v}, (\{\bndclr{v}\} \cup V_0 \cup \ldots \cup V_n, E \cup E_0 \cup \ldots \cup E_n)&(2)\\
\quad \textnormal{when}~\bndclr{v_i}, (V_i, E_i) = \ident{bind-expr}_{\Gamma, \Delta}(e_i)
~\textnormal{and}~\Delta(\bknd{mem}(m),[(\bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v_n}, \blbl{arg}(n))])\!\downarrow\\
\quad \textnormal{let}~\bndclr{v} = \bnd{mem}(m, s), s~\textnormal{fresh}
~\textnormal{and}~E = \{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v},\bndclr{v_n}, \blbl{arg}(n)) \}
\\[1em]
\ident{bind-expr}_{\Gamma, \Delta}(\lambda x \rightarrow e) = \bndclr{v}, (\{\bndclr{v}\} \cup V, \{e\} \cup E)&(3)\\
\quad \textnormal{when}~\Gamma_1 = \Gamma \cup \{ x, \bnd{var}(x) \}
~\textnormal{and}~\bndclr{v_0}, (V, E) = \ident{bind-expr}_{\Gamma_1, \Delta}(e)
~\textnormal{and}~\bndclr{v} = \Delta(\bknd{fun}(x),[(\bndclr{v_0}, \blbl{body})])\\
\quad \textnormal{let}~e = (\bndclr{v}, \bndclr{v_0}, \blbl{body})
\\[1em]
\ident{bind-expr}_{\Gamma, \Delta}(\lambda x \rightarrow e) = \bndclr{v}, (\{\bndclr{v}\} \cup V, \{e\} \cup E)&(4)\\
\quad \textnormal{when}~\Gamma_1 = \Gamma \cup \{ x, \bnd{var}(x) \}
~\textnormal{and}~\bndclr{v_0}, (V, E) = \ident{bind-expr}_{\Gamma_1, \Delta}(e)
~\textnormal{and}~\Delta(\bknd{fun}(x),[(\bndclr{v_0}, \blbl{body})])\!\downarrow\\
\quad \textnormal{let}~\bndclr{v} = \bnd{fun}(x, s), s~\textnormal{fresh}
~\textnormal{and}~e = (\bndclr{v},\bndclr{v_0},\blbl{body})
\\[1em]
\ident{bind-expr}_{\Gamma, \Delta}(o) = \bnd{val}(o), (\{ \bnd{val}(o) \}, \emptyset) &(5)
\\[1em]
\ident{bind-expr}_{\Gamma, \Delta}(x) = \bndclr{v}, (\{ \bndclr{v} \}, \emptyset)~\textnormal{when}~\bndclr{v} = \Gamma(x)&(6)
\end{array}
\end{equation*}
\caption{Binding rules that define a construction of a dependency graph for an expression.}
\label{fig:binding-rules-expr}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
\begin{equation*}
\hspace{-3.5em}
\begin{array}{ll}
\ident{bind-prog}_{\Gamma, \Delta}(\kvd{let}~x=e; c_2; \ldots; c_n) = \bndclr{v_1};\ldots;\bndclr{v_n}, (\{\bndclr{v_1}\} \cup V \cup V_1, E \cup E_1)
  \hspace{9.35em}&(7)\\
\quad \textnormal{let}~\bndclr{v_1}, (V_1,E_1) = \ident{bind-expr}_{\Gamma,\Delta}(e_1)~\textnormal{and}~\Gamma_1 = \Gamma \cup \{(x,\bndclr{v_1})\} \\
\quad \textnormal{and}~\bndclr{v_2}; \ldots; \bndclr{v_n}, (V, E) = \ident{bind-prog}_{\Gamma_1, \Delta}(c_2; \ldots; c_n)
\\[1em]
\ident{bind-prog}_{\Gamma, \Delta}(e; c_2; \ldots; c_n) = \bndclr{v_1};\ldots;\bndclr{v_n}, (\{\bndclr{v_1}\} \cup V \cup V_1, E \cup E_1)&(8)\\
\quad \textnormal{let}~\bndclr{v_1}, (V_1,E_1) = \ident{bind-expr}_{\Gamma,\Delta}(e)
~\textnormal{and}~\bndclr{v_2}; \ldots; \bndclr{v_n}, (V, E) = \ident{bind-prog}_{\Gamma_1, \Delta}(c_2; \ldots; c_n)
\\[1em]
\ident{bind-prog}_{\Gamma, \Delta}([]) = [], (\emptyset, \emptyset)&(9)
\end{array}
\end{equation*}
\caption{Binding rules that define a construction of a dependency graph for a program.}
\label{fig:binding-rules-prog}
\end{figure*}


% --------------------------------------------------------------------------------------------------

\subsection{Binding expressions to a graph}
\label{sec:formal-bind}

After parsing updated code, we update the dependency graph and link each node of the abstract
syntax tree to a node of the dependency graph. This process is called
binding and is defined by the \ident{bind-expr} function (Figure~\ref{fig:binding-rules-expr})
and \ident{bind-prog} function (Figure~\ref{fig:binding-rules-prog}). Both functions are
annotated with a lookup table $\Delta$ discussed in Section~\ref{sec:formal-deps} and a variable
context $\Gamma$. The variable context is a map from variable names to dependency graph nodes and
is used for variables bound using \kvd{let} binding.

When applied on an expression $e$, binding $\ident{bind-expr}_{\Gamma,\Delta}(e)$ returns
a node $\bndclr{v}$ corresponding to the expression $e$ paired with a dependency graph $(V, E)$.
In the graph, $V$ is a set of nodes $\bndclr{v}$ and $E$ is a set of labeled edges
$(\bndclr{v_1}, \bndclr{v_2}, \blblclr{l})$. We attach the label directly to the edge rather than
keeping a separate colouring function as this makes the formalisation simpler.
The $\ident{bind-prog}_{\Gamma,\Delta}$ function works similarly, but takes a sequence of
commands and returns a sequence of nodes.

\subsubsection{Binding expressions.} When binding member access, we use \ident{bind-expr} recursively
to get a node and a dependency graph for each sub-expression. The nodes representing sub-expressions are
then used as dependencies for lookup into $\Delta$, together with their labels. If a node already
exists in $\Delta$ it is reused (1). Alternativelym, we create a new node containing a fresh symbol~(2).

If a lambda function uses its argument, we will not be able to evaluate its body. In this case, the
graph node bound to a function will depend on a synthetic node $\bnd{var}(x)$ that represents the
variable with unknown value. When binding a function, we create the synthetic variable and add it
to the variable context $\Gamma_1$ before binding the body. As with member access, the node
representing a function may (3) or may not (4) be already present in the lookup table.

\subsubsection{Binding programs.} When binding a program, we bind the first command and then
recursively process remaining commands until we reach an empty list of commands (9).
For \kvd{let} binding (7), we bind the expression $e$ assigned to the variable to obtain a
graph node $\bndclr{v_1}$. We then bind the remaining commands using a variable context $\Gamma_1$
that maps the value of the variable to the graph node $\bndclr{v_1}$. The variable context is used
when binding a variable (6) and so all variables declared using \kvd{let} binding will be bound to
a graph node representing the value assigned to the variable. When the command is just an
expression (8), we bind the expression using \ident{bind-expr}.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\begin{array}{l}
\ident{update}_{V,E}(\Delta_{i-1}) = \Delta_i~\textnormal{such that:}
\\[0.75em]
\quad\Delta_{i}(\bknd{mem}(m), [(\bndclr{v_0},\blbl{arg}(0)),\ldots, (\bndclr{v_n},\blbl{arg}(n))]) = \bnd{mem}(m, s)\\
\quad\quad \textnormal{when}~\bnd{mem}(m, s) \in V
~\textnormal{and}~(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E~\textnormal{for}~i\in 0,..,n
\\[0.75em]
\quad\Delta_{i}(\bknd{fun}(x), [(\bndclr{v_1},\blbl{body})]) = \bnd{fun}(x, s)\\
\quad\quad \textnormal{when}~\bnd{fun}(x, s) \in V
~\textnormal{and}~(\bnd{fun}(x, s), \bndclr{v_1}, \blbl{body}) \in E
\\[0.75em]
\quad\Delta_{i}(\bkndclr{v}) = \Delta_{i-1}(\bkndclr{v})\quad \textnormal{(otherwise)}
\end{array}
\end{equation*}
\vspace{-1em}
\caption{Updating the node cache after binding a new graph}
\label{fig:loop}
\vspace{-0.5em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Edit and rebind loop}

The binding process formalised in Section~\ref{sec:formal-bind} specifies how to update the
dependency graph after updated program text is parsed. During live coding, this is done
repeatedly as the programmer edits code. Throughout the process, we maintain a series of
lookup table states $\Delta_0, \Delta_1, \Delta_2, \ldots$ The initial lookup table is
empty, i.e.~$\Delta_0 = \emptyset$. At a step $i$, we parse a program $p_i$ (consisting of
several commands) and obtain a new dependency graph using the previous $\Delta$. The result is
a sequence of nodes corresponding to commands of the program and a graph $(V, E)$:
%
\begin{equation*}
\bndclr{v_1}; \ldots; \bndclr{v_n}, (V, E) = \ident{bind-prog}_{\emptyset, \Delta_{i-1}}(p_i)
\end{equation*}
%
The new state of the cache is computed by calling the $\ident{update}_{V, E}(\Delta_{i-1})$ function
defined in Figure~\ref{fig:loop}. The function adds newly created nodes from the graph
$(V, E)$ to the previous cache $\Delta_{i-1}$ and returns a new cache $\Delta_{i}$. We only cache
nodes for function and member accesses -- nodes for variables and primitive values will remain
the same thanks to the way they are constructed.

% ==================================================================================================

\section{Computing live previews}
\label{sec:previews}

The binding process described in the previous section constructs a dependency graph after code
changes. The nodes in the dependency graph correspond to individual operations that will be performed
when running the program. When evaluating a preview, we attach (partial) results to
nodes of the graph. Since the binding process reuses nodes when their dependencies do not change,
previews for expressions (or sub-expressions) of a program can be reused when updating a preview.

In this section, we describe how previews are evaluated. The evaluation is done over the dependency
graph, rather than over the structure of the program expressions as in the operational semantics
given in Section~\ref{sec:calculus-semantics}. We analyse the preview evaluation formally in
Section~\ref{sec:evaluation} and show that the resulting previews are the same as the result we
would get by directly evaluating the code and, also, that no recomputation occurs when code is
edited in certain ways.

% --------------------------------------------------------------------------------------------------

\subsection{Previews and delayed previews}

Programs in the data exploration calculus consist of sequence of commands. Those can always be
evaluated to a value with a preview that can be displayed to the user. However, we also support
previews for all sub-expressions. This can be problematic if the current sub-expression is inside
the body of a function. For example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{top} = \ident{movies}.\ident{take}(\num{10}).\ident{map}(\lambda x \rightarrow x.\ident{getReleased}().\ident{format}(\str{dd-mm-yyyy}))
\end{array}
\end{equation*}
%
Here, we can directly evaluate sub-expressions \ident{movies} and $\ident{movies}.\ident{take}(\num{10})$,
but not $x.\ident{getReleased}()$ and $x.\ident{getReleased}().\ident{format}(\str{dd-mm-yyyy})$
because they contain a free variable $x$. Our preview evaluation algorithm addresses this by
producing two kinds of previews. A \emph{fully evaluated preview} is just a value, while
a \emph{delayed preview} is a partially evalauted expression with free variables:

\begin{equation*}
\begin{array}{rcll}
p&=&o \lsep  \lambda x\rightarrow e&\quad(\textit{Fully evaluated previews})\\
d&=&p \lsep  \llbracket e \rrbracket_\Gamma&\quad(\textit{Evaluated and delayed previews})\\
\end{array}
\end{equation*}
%
A fully evaluated preview $p$ can be either a primitive object or a function value with no free
variables. A possibly delayed preview $d$ can be either an evaluated preview $p$ or an expression
$e$ that requires variables $\Gamma$. For simplicity, we use an untyped language and so $\Gamma$
is just a list of variables $x_1, \ldots, x_n$.

A delayed preview is not necessarily the body of a lambda function as it appears in the source
code. We partially evaluate sub-expressions of the body that do not have free variables or that
have free variables bound by an earlier let binding.

Our implementation does not currently display
delayed previews to the user, but there is a number of possible approaches for doing that.
Most interestingly, since lambda functions always appear as arguments of a member access, we could
force the evaluation of the surrounding expression, capture (a number of) values passed as inputs
to the lambda function and display a preview based on those. Finally, in Section~\ref{sec:design},
we also consider a more speculative design for an abstraction mechanism that supports live previews
that could, in some cases, replace lambda function.

% --------------------------------------------------------------------------------------------------

\begin{figure*}[b]
\begin{equation*}
\hspace{-2.5em}
\begin{array}{l}
\inference[\rname{lift-expr}~]
  {\bndclr{v} \Downarrow \llbracket e \rrbracket_\Gamma}
  {\bndclr{v} \Downarrow_{\ident{lift}} \llbracket e \rrbracket_\Gamma}
\\
\\
\inference[\rname{lift-prev}~]
  {\bndclr{v} \Downarrow p}
  {\bndclr{v} \Downarrow_{\ident{lift}} \llbracket p \rrbracket_\emptyset}
\\
\\
\inference[\rname{val}~]
  {~}
  {\bnd{val}(o) \Downarrow o }
\\
\\
\inference[\rname{var}~]
  {~}
  {\bnd{var}(x) \Downarrow \llbracket x \rrbracket_x}
  \\[0.5em]~
\end{array}
\qquad\quad
\begin{array}{l}
\inference[\rname{fun-val}~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow p }
  { \bnd{fun}(x, s) \Downarrow \lambda x\rightarrow p }
\\
\\
\inference[\rname{fun-bind}~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow \llbracket e \rrbracket_{x} }
  { \bnd{fun}(x, s) \Downarrow \lambda x\rightarrow e }
\\
\\
\inference[\rname{fun-expr}~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow \llbracket e \rrbracket_{x,\Gamma} }
  { \bnd{fun}(x, s) \Downarrow \llbracket \lambda x\rightarrow e \rrbracket_\Gamma }
\\[0.5em]~
\end{array}
\end{equation*}
\begin{equation*}
\hspace{-2.5em}
\begin{array}{l}
\inference[\rname{mem-val}~]
  { \forall i\in\{0\ldots k\}.(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E & \bndclr{v_i} \Downarrow p_i
    & p_0.m(p_1, \ldots, p_k) \rightsquigarrow_\epsilon p }
  { \bnd{mem}(m, s) \Downarrow p }
\\
\\
\inference[\rname{mem-expr}~]
  { \forall i\in\{0\ldots k\}.(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E & \exists j\in\{0\ldots k\}.\bndclr{v_j}\diagup\hspace{-1em}\Downarrow p_j
   & \bndclr{v_i} \Downarrow_{\ident{lift}} \llbracket e_i \rrbracket_{\Gamma_i}  }
  { \bnd{mem}(m, s) \Downarrow \llbracket e_0.m(e_1, \ldots, e_k) \rrbracket_{\Gamma_0,\ldots,\Gamma k} }
\\
\end{array}
\end{equation*}

\caption{Rules that define evaluation of previews over a dependency graph for a program}
\label{fig:eval}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\subsection{Evaluation of previews}
The evaluation of previews is defined in Figure~\ref{fig:eval}. Given a dependency graph $(V, E)$,
we define a relation $\bndclr{v}\Downarrow d$ that evaluates a sub-expression corresponding to
the node $\bndclr{v}$ to a possibly delayed preview $d$. The nodes $V$ and edges $E$ of the
dependency graph are parameters of the $\Downarrow$ relation, but they do not change during the
evaluation and so we do not explicity write them.

The auxiliary relation $\bndclr{v}\Downarrow_{\ident{lift}} d$ always evaluates
to a delayed preview. If the ordinary evaluation returns a delayed preview, so does the auxiliary
relation \rname{lift-expr}. If the ordinary evaluation returns a value, the value is wrapped
into a delayed preview requiring no variables \rname{lift-prev}.
%
A node representing a value is evaluated to a value \rname{val} and a node representing
an unbound variable is reduced to a delayed preview that requires the variable and returns its
value~\rname{var}.

For member access, we distinguish two cases. If all arguments evaluate to values \rname{member-val},
then we use the evaluation relation defined by external libraries $\rightsquigarrow_\epsilon$ to
immediately evaluate the member access and produce a value. If some of the arguments are
delayed \rname{member-expr}, because the member access is inside the body of a lambda function,
we produce a delayed member access expression that requires the union of the variables
required by the individual arguments.

The evaluation of function values is similar, but requires three cases. If the body can
be reduced to a value with no unbound variables \rname{fun-val}, we return a lambda function that
returns the value. If the body requires only the bound variable \rname{fun-bind}, we return a
lambda function with the delayed preview as the body. If the body requires further variables,
the result is a delayed preview.

\subsection{Caching of evaluated previews}
\label{sec:previews-cache}

For simplicity, the relation $\Downarrow$ in Figure~\ref{fig:eval} does not specify how previews
are cached and linked to graph nodes. In practice, this is done by maintaining a lookup table
from graph nodes $\bndclr{v}$ to (possibly delayed) previews $p$.
Whenever $\Downarrow$ is used to obtain a preview for a graph node, we first
attempt to find an already evaluated preview using the lookup table. If the preview has not
been previously evaluated, we evaluate it and add it to the lookup table.

The cached evaluated previews can be reused in two ways. First, multiple nodes can
depend on one sub-graph in a single dependency graph (if the same sub-expression appears
twice in the program). Second, the keys of the lookup table are graph nodes and nodes are
reused when a new dependency graph is constructed after the user edits the source code.

\subsection{Theories of delayed previews}
The operational semantics presented in this paper serves two purposes. It gives a simple guide
for implementing text-based live coding environments for data science and we use it to prove that
our optimized way of producing live previews is correct. However, some aspects of our mechanism
are related to important work in semantics of programming languages and deserve to be mentioned.

The construction of delayed previews is related to meta-programming. Assuming
we have delayed previews $\llbracket e_0 \rrbracket_x$ and $\llbracket e_1 \rrbracket_y$ and
we invoke a member $m$ on $e_0$ using $e_1$ as an argument. To do this, we construct a new
delayed preview $\llbracket e_0.m(e_1) \rrbracket_{x, y}$. This operation is akin to expression
splicing from meta-programming \cite{metaml,quotations}.

The semantics of delayed previews can be more formally captured by Contextual Modal Type Theory
(CMTT) \cite{cmtt} and comonads \cite{cmtt-denotation}. In CMTT, $\lbrack \Psi \rbrack A$ denotes
that a proposition $A$ is valid in context $\Psi$, which is similar to our delayed previews written
as $\llbracket A \rrbracket_\Psi$. CMTT defines rules for composing context-dependent propositions
that would allow us to express the splicing operation used in \rname{mem-expr}. In categorical
terms, the context-dependent proposition can be modeled as an indexed comonad \cite{effectrev,graded}.
The evaluation of a preview with no context dependencies (built implicitly into our evaluation rules)
corresponds to the counit operation of a comonad and would be explicitly written as
$\llbracket A \rrbracket_\emptyset \rightarrow A$.

% ==================================================================================================

\section{Evaluating correctness and effectiveness}
\label{sec:evaluation}

The use of a dependency graph when evaluating previews makes it possible to cache partial results
through a mechanism discussed in Section~\ref{sec:formal-deps} and Section~\ref{sec:previews-cache}.
The mechanism satisfies two properties. First, if we evaluate a preview using dependency
graph with caching, it is the same as the value we would obtain by evaluating the expression
directly. Second, the evaluation of previews using dependency graphs reuses -- in some cases --
previously evaluated partial results. In other words, we show that the mechanism is correct
and implements an effective optimization. We discuss correctness first and then evaluate
effectiveness, both theoretically (Section~\ref{sec:evaluation-reuse}) and empirically
(Section~\ref{sec:evaluation-empirical}).

% --------------------------------------------------------------------------------------------------

\subsection{Correctness of previews}
\label{sec:evaluation-correctness}

To show that the previews are correct, we prove two properties. Correctness
(Theorem~\ref{thm:correcntess}) guarantees that, no matter how a dependency graph is constructed,
when we use it to evaluate previews for a program, the previews are the same as the values we
would obtain by evaluating the program commands directly. Determinacy (Theorem~\ref{thm:determinacy})
guarantees that if we cache a preview for a graph node and update the graph, the preview we would
evaluate using the updated graph would be the same as the cached preview.

To simplify the proofs, we consider programs without let bindings. This is possible, because
eliminating let bindings does not change the result of evaluation, as shown earlier in
Lemma~\ref{thm:let-lang-elimination}, and it also does not change the constructed dependency graph
as shown below in Lemma~\ref{thm:let-grp-elimination}.

\begin{lem}[Let elimintion for a dependency graph]
\label{thm:let-grp-elimination}
Given programs $p_1, p_2$ such that $p_1 \rightsquigarrow_\ident{let} p_2$ and a lookup table
$\Delta_0$ then if $\bndclr{v_1}; \ldots; \bndclr{v_n}, (V, E) = \ident{bind-prog}_{\emptyset, \Delta_0}(p_1)$ and
$\bndclr{v'_1};\ldots;\bndclr{v'_n}, (V', E') = \ident{bind-prog}_{\emptyset, \Delta_1}(p_2)$ such that $\Delta_1 = \ident{update}_{V, E}(\Delta_0)$
then for all $i$, $\bndclr{v_i} = \bndclr{v'_i}$ and also $(V, E) = (V', E')$.
\end{lem}
\begin{proof}
Assume $p_1 = c_1; \ldots; c_{k-1}; \kvd{let}~x=e; c_{k+1};\ldots; c_n$ and the let binding is
eliminated resulting in $p_2 = c_1; \ldots; c_{k-1}; e; c_{k+1}[x\leftarrow e];\ldots; c_n[x\leftarrow e]$.
When binding $p_1$, the case $\ident{bind-prog}_{\Gamma,\Delta}(\kvd{let}~x=e)$ is handled using (7)
and the node resulting from binding $e$ is added to the graph $V, E$. It is then referenced each
time $x$ appears in subsequent commands $c_{k+1}; \ldots; c_n$.
When binding $p_2$, the node resulting from binding $e$ is a primitive value or a node already
present in $\Delta_1$ (added by $\ident{update}_{V, E}$) and is reused each time
$\ident{bind-expr}_{\Gamma,\Delta_1}(e)$ is called.
\end{proof}

The Lemma~\ref{thm:let-grp-elimination} provides a way of removing let bindings from a program,
such that the resulting dependency graph remains the same. Here, we bind the original program
first, which adds the node for $e$ to $\Delta$. In our implementation, this is not needed
because $\Delta$ is updated while the graph is being constructed using $\ident{bind-expr}$.
To keep the formalisation simpler, we separate the process of building the dependency graph
and updating $\Delta$ and thus Lemma~\ref{thm:let-grp-elimination} requires an extra binding step.

Now, we can show that, given a let-free expression, the preview obtained using a correctly
constructed dependency graph is the same as the one we would obtain by directly evaluating the
expression. This requires a simple auxiliary lemma.

\begin{lem}[Lookup inversion]
\label{thm:lemma-lookup}
Given $\Delta$ obtained using \ident{update} as defined in Figure~\ref{fig:loop} then:
\begin{itemize}
\raggedright
\item[--] If $\bndclr{v}=\Delta(\bknd{fun}(x),[(\bndclr{v_0}, \blblclr{l_0})])$
then $\bndclr{v}=\bnd{fun}(x, s)$ for some $s$.
\item[--] If $\bndclr{v}=\Delta(\bknd{mem}(m),[(\bndclr{v_0}, \blblclr{l_0}), \ldots, (\bndclr{v_n}, \blblclr{l_n})])$
then $\bndclr{v}=\bnd{mem}(m, s)$ for some $s$.
\end{itemize}
\end{lem}
\begin{proof}
By construction of $\Delta$ in Figure~\ref{fig:loop}.
\end{proof}

\begin{theorem}[Term preview correctness]
\label{thm:let-free-correct}
Given a term $t$ that has no free variables, together with a lookup table $\Delta$ obtained
from any sequence of programs using $\ident{bind-prog}$ (Figure~\ref{fig:binding-rules-prog}) and
$\ident{update}$ (Figure~\ref{fig:loop}), then
let $\bndclr{v}, (V, E) = \ident{bind-expr}_{\emptyset, \Delta}(t)$.

\vspace{0.25em}
\noindent
If $\bndclr{v}\Downarrow p$
over a graph $(V, E)$ then $p = o$ for some value $o$ and $t \rightsquigarrow^{*} o$.
\end{theorem}

\begin{proof}
First note that, when combining recursively constructed sub-graphs, the \ident{bind-expr} function
adds new nodes and edges leading from those new nodes. Therefore, an evaluation using~$\Downarrow$
over a sub-graph will also be valid over the new graph -- the newly added nodes and edges do not introduce
non-determinism to the rules given in Figure~\ref{fig:eval}.

We prove a more general property showing that for any $e$, its binding
$\bndclr{v}, (V, E) = \ident{bind-expr}_{\emptyset, \Delta}(e)$ and any evaluation context $C$
such that $C[e]\rightsquigarrow o$ for some $o$, one of the following holds:
%
\begin{enumerate}
\item[a.] If $FV(e)\,=\,\emptyset$ then $\bndclr{v} \Downarrow p$ for some $p$ and $C[p] \rightsquigarrow o$
\item[b.] If $FV(e)\,\neq\,\emptyset$ then $\bndclr{v} \Downarrow \llbracket e_p \rrbracket_{FV(e)}$ for some $e_p$ and $C[e_p] \rightsquigarrow o$
\end{enumerate}
%
In the first case, $p$ is a value, but it is not always the case that $e \rightsquigarrow^{*} p$,
because $p$ may be lambda function and preview evaluation may reduce sub-expression in the body of
the function. Using a context $C$ in which the value reduces to an object avoids this problem.

The proof of the theorem follows from the more general property. Using a context $C[-]=-$, the
term $t$ reduces $t \rightsquigarrow^{*}t' \rightsquigarrow_\epsilon o$ for some $o$ and the
preview $p$ is a value $o$ because $C[p] = p = o$.
The proof is by induction over the binding process, which follows the structure of the expression.
The full proof is shown in Appendix~\ref{sec:app-correctness}.
\end{proof}

\noindent
The correctness theorem combines the previous two results.

\begin{theorem}[Program preview correctness]
\label{thm:correcntess}
Consider a program $p=c_1;\ldots;c_n$ that has no free variables, together with a lookup table
$\Delta_0$ obtained from any sequence of programs using $\ident{bind-prog}$
(Figure~\ref{fig:binding-rules-prog}) and $\ident{update}$ (Figure~\ref{fig:loop}). Assume a
let-free program $p'=t_1;\ldots;t_n$ such that $p\rightsquigarrow^{*}_\ident{let}p'$.

\vspace{0.25em}
\noindent
Let $\bndclr{v_1};\ldots;\bndclr{v_n}, (V, E) = \ident{bind-prog}_{\emptyset, \Delta_0}(p)$
and define updated lookup table $\Delta_1=\ident{update}_{V, E}(\Delta_0)$ and
let $\bndclr{v'_1};\ldots;\bndclr{v'_n}, (V', E') = \ident{bind-prog}_{\emptyset, \Delta_1}(p)$.

\vspace{0.25em}
\noindent
If $\bndclr{v'_i}\Downarrow p_i$ over a graph $(V', E')$ then $p_i=o_i$ for some value $o_i$ and
$t_i \rightsquigarrow o_i$.
\end{theorem}
\begin{proof}
Direct consequence of Lemma~\ref{thm:let-grp-elimination} and Theorem~\ref{thm:let-free-correct}.
\end{proof}

As discussed earlier, our implementation updates $\Delta$ during the recursive binding process and
so a stronger version of the property holds -- namely, previews calculated over a graph obtained
directly for the original program $p$ are the same as the values of the fully evaluated program.
We note that this is the case, but do not show it formally to aid the clarity of our formalisation.

The second important property that guarantees that our mechanism always displays correct previews
is determinacy. This makes it possible to cache the previews evaluated using~$\Downarrow$ using
the corresponding graph node as a lookup key.

\begin{theorem}[Program preview determinacy]
\label{thm:determinacy}
For some $\Delta$ and for any programs $p, p'$, assume that the first program is bound,
i.e.~$\bndclr{v_1};\ldots;\bndclr{v_n}, (V, E) = \ident{bind-prog}_{\emptyset, \Delta}(p)$,
the graph node cache is updated $\Delta' = \ident{update}_{V, E}(\Delta)$ and the second program is
bound, i.e.~$\bndclr{v'_1};\ldots;\bndclr{v'_m}, (V', E') = \ident{bind-prog}_{\emptyset, \Delta'}(p')$.
Now, for any $\bndclr{v}$, if $\bndclr{v} \Downarrow p$ over $(V, E)$ then also
 $\bndclr{v} \Downarrow p$ over $(V', E')$.
\end{theorem}
\begin{proof}
By induction over $\Downarrow$ over $(V, E)$, we show that the same evaluation rules also
apply over $(V', E')$. This is the case, because graph nodes added to $\Delta'$ by $\ident{update}_{V, E}$
are added as new nodes in $\ident{bind-prog}_{\emptyset, \Delta'}$ and
nodes and edges of $(V, E)$ used during the evaluation are unaffected.
\end{proof}

The mechanism used for caching previews, as discussed in Section~\ref{sec:previews-cache},
keeps a preview or a partial preview $d$ in a lookup table indexed by nodes $\bndclr{v}$. The
Theorem~\ref{thm:determinacy} guarantees that this is a valid strategy. As we update dependency
graph during code editing, previous nodes will continue representing the same sub-expressions.

% --------------------------------------------------------------------------------------------------

\subsection{Reuse of previews}
\label{sec:evaluation-reuse}

In the motivating example given in Section~\ref{sec:intro}, the data analyst first extracted a
constant value into a let binding and then modified a parameter of the last method call in a call
chain. We argued that a live coding environment should reuse partially evaluated previews for these
two cases. We now show that this is, indeed, the case in our system.

In this section, we identify a number of code edit operations where the previously evaluated
values for a sub-expression can be reused. The list of operations is shown in Figure~\ref{fig:operations}.
To express the operations we define an editing context $K$ which is defined
similarly to evaluation context $C$ from Figure~\ref{fig:dec-calculus}, but captures sub-expressions
appearing anywhere in the program.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\raggedright
\vspace{0.5em}
\hspace{1.5em}{\small\sffamily Edit contexts of expressions}
\begin{equation*}
\begin{array}{lcl}
K_e[-] &=& K_e[-].m(e_1, \ldots, e_n) ~\lsep~ e.m(e_1, \ldots, e_{l-1}, K_e[-], e_{l+1},\ldots , e_n) ~\lsep~ -\\
K_c[-] &=& \kvd{let}~x = K_e[-] ~\lsep~ K_e[-]\\
\end{array}
\end{equation*}

\vspace{0.5em}
\hspace{1.5em}{\small\sffamily Code edit operations preserving preview for a sub-expression}

\hspace{4em}\begin{minipage}[c]{0.82\textwidth}
  \raggedright\setlength{\parindent}{-1em}

  \ername{let-intro-var}
  $\overline{c_1}; \preview{e}; \overline{c_2}$ changes to
  $\overline{c_1}; \kvd{let}\,x = e; \preview{x}; \overline{c_2}$ where $x$ is a fresh name.

  \ername{let-intro-ins}
  $\overline{c_1}; \overline{c_2}; \preview{K_c[e]}; \overline{c_3}$ is changed to
  $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; \preview{K_c[x]}; \overline{c_3}$ via
  a semantically non-equivalent expression
  $\overline{c_1}; \overline{c_2}; K_c[x]; \overline{c_3}$ where $x$ is free.

  \ername{let-intro-del}
  $\overline{c_1}; \overline{c_2}; \preview{K_c[e]}; \overline{c_3}$ is changed to
  $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; \preview{K_c[x]}; \overline{c_3}$ via
  an expression $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; K_c[e]; \overline{c_3}$
  with unused variable $x$.

  \ername{let-elim-del}
  $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; \preview{K_c[x]}; \overline{c_3}$ is changed to
  $\overline{c_1}; \overline{c_2}; \preview{K_c[e]}; \overline{c_3}$ via
  a semantically non-equivalent expression
  $\overline{c_1}; \overline{c_2}; K_c[x]; \overline{c_3}$ where $x$ is free.

  \ername{let-elim-ins}
  $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; \preview{K_c[x]}; \overline{c_3}$ is changed to
  $\overline{c_1}; \overline{c_2}; \preview{K_c[e]}; \overline{c_3}$ via
  an expression $\overline{c_1}; \kvd{let}\,x=e; \overline{c_2}; K_c[e]; \overline{c_3}$
  with unused variable $x$.

  \ername{edit-mem}
  $\overline{c_1}; K_c[\preview{e_0}.m(\overline{e})]; \overline{c_2}$ is changed to
  $\overline{c_1}; K_c[\preview{e_0}.m'(\overline{e'})]; \overline{c_2}$

  \ername{edit-let}
  $\overline{c_1}; \kvd{let}\,x=e_1; \overline{c_2}; K_c[\preview{e_2}]; \overline{c_3}$ is changed to
  $\overline{c_1}; \kvd{let}\,x=e'_1; \overline{c_2}; K_c[\preview{e_2}]; \overline{c_3}$ \hspace{2em} when
  $x\notin FV(e_2)$.
\end{minipage}

\caption{Code edit operations that preserve previously evaluated preview}
\label{fig:operations}
\end{figure}

% --------------------------------------------------------------------------------------------------

We use the notation $\preview{e}$ to mark the part of the expressions before and after the edit
that have the same value that will not need to be recomputed after the change and we write
$\overline{c}$ and $\overline{e}$ for a list of commands and expressions, respectively.
In some of the edit operations, we also specify an intermediate program that is, in some cases,
semantically different and only has a partial preview. This illustrates a typical way of
working with code in a text editor using cut and paste operations. For example, in
\rname{let-intro-ins}, we assume that the analyst cuts a sub-expression $e$, replaces it with
a variable $x$ and then adds a let binding for a variable $x$ and inserts the expression $e$
from the clipboard. Edit with the same result is captured by \rname{let-intro-del} but here
the analyst first inserts the let binding and then replaces the sub-expression $e$ with a
variable $x$.

The of preview-preserving code edit operations includes several ways of introducing a let
binding, several ways of eliminating a let binding and two edit operations where the data anlyst
modifies an unrelated part of the program. It is worth noting that the list is not exhaustive.
Rather, it aims to illustrate some of the typical operations that the data analyst might perform
when writing code.

Theorem~\ref{thm:preview-reuse} proves that the operations given in Figure~\ref{fig:operations}
preserve the preview for a marked sub-expression. It relies on the following lemma that
characterizes one of the common kinds of edits more generally. Given two versions of a program
that both contain the same sub-expression $e$, if the let bindings that define the values of
variables used in $e$ do not change, then the graph node assigned to $e$ will be the same
when binding the original and the updated program.

% --------------------------------------------------------------------------------------------------

\begin{lem}[Binding sub-expressions]
\label{thm:sub-expr}
Assume we have programs $p_1 = c_1; \ldots; c_k; K_c[e]; c_{k+1};\ldots; c_n$ and
$p_2 = c'_1; \ldots; c'_k; K'_c[e]; c'_{k+1};\ldots;c'_n$ and $I\subseteq \{1\ldots k\}$ such
that $\forall i\!\in\!I.\,c_i\!=\!c'_i$ and for each $x \in \bigcup_{i\in I}FV(c_i) \cup FV(e)$
there exists $j\in I$ such that $c_j = \kvd{let}\,x=e$ for some $e$.
%
Given any $\Delta$, assume that the the first program is bound,
i.e.~$\bndclr{v_1};\ldots;\bndclr{v_n}, (V, E) = \ident{bind-prog}_{\emptyset, \Delta}(p_1)$,
the cache is updated $\Delta' = \ident{update}_{V, E}(\Delta)$ and the second
program is bound,
i.e.~$\bndclr{v'_1};\ldots;\bndclr{v'_n}, (V', E') = \ident{bind-prog}_{\emptyset, \Delta'}(p_2)$.

Now, assume $\bndclr{v}, G = \ident{bind-expr}_{\Gamma, \Delta}(e)$ and
$\bndclr{v'}, G' = \ident{bind-expr}_{\Gamma', \Delta'}(e)$ are the recursive calls to bind
$e$ during the first and the second binding, respectively. Then, the graph nodes assigned to the
sub-expression $e$ are the same, i.e.~$\bndclr{v} = \bndclr{v'}$.
\end{lem}
\begin{proof}
First, assuming that $\forall x\in FV(e). \Gamma(x) = \Gamma'(x)$, we show by induction over the binding process of $e$
for the first program that the result is the same. In cases (1) and (3), the updated $\Delta'$
contains the required key and so the second binding proceeds using the same case. In cases
(2) and (4), the second binding reuses the node created by the first binding using case (1) and
(3), respectively. Cases (5) and (6) are the same.

Second, when binding let bindings in $c_1; \ldots; c_k$, the initial $\Gamma = \emptyset$ during
both bindings. Nodes added to $\Gamma$ and $\Gamma'$ for commands $c_j$ such that $j\in I$ are
the same and nodes added for remaining commands do not add any new nodes referenced from $e$ and
so $\bndclr{v} = \bndclr{v'}$ using the above.
\end{proof}

\begin{theorem}[Preview reuse]
\label{thm:preview-reuse}
Given the sequence of expressions as specified in Figure~\ref{fig:operations}, if the expressions
are bound in sequence and graph node cache updated as specified in Figure~\ref{fig:loop}, then
the graph nodes assigned to the specified sub-expressions are the same.
\end{theorem}
\begin{proof}
Cases \rname{edit-let} and \rname{edit-mem} are direct consequences of Lemma~\ref{thm:sub-expr};
for \rname{let-intro-var}, the node assigned to $x$ is the node assigned to $e$ which is the
same as before the edit from Lemma~\ret{thm:sub-expr}.
Cases \rname{let-intro-ins} and \rname{let-intro-del} are similar to \rname{let-intro-var}, but
also require using induction over the binding of $K_c[e]$. Finally, cases \rname{let-elim-ins}
and \rname{let-elim-del} are similar and also use Lemma~\ref{thm:sub-expr}
together with induction over the binding of $K_c[x]$.
\end{proof}

% --------------------------------------------------------------------------------------------------

\subsection{Empirical evaluation of efficiency}
\label{sec:evaluation-empirical}

The key performance claim about our method of providing instantaneous feedback is that it is more
efficient than recomputing values for the whole program (or the current command) after every
keystroke. In the previous section, we formally proved that this is true and gave examples of
code edit operations that do not cause recomputation. In this section, we further support this
claim with an empirical evaluation. The purpose of this section is not to precisely evaluate
overheads of our implementation, but to compare how much recomputation different evaluation
strategies perform.

For the purpose of the evaluation, we use a simple image manipulation library that provides
operations for loading, greyscaling, bluring and combining images. We compare delays in
updating the preview for three different evaluation strategies, while performing the same
sequence of code edit operations. Using image processing as an example gives us a way to
visualize the reuse of previously computed values. As in a typical data exploration scenario,
the individual operations are relatively expensive compared to the overheads of building the
dependency graph.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\raggedright

\vspace{0.5em}\hspace{1.5em}{\small\sffamily (1) Enter the following code and then change parameter of blur from 4 to 8:}
\begin{equation*}
\begin{array}{l}
\ident{image}.\ident{load}(\str{shadow.png}).\ident{greyScale}().\ident{blur}(\num{4})
\end{array}
\end{equation*}

\vspace{0.5em}\hspace{1.5em}{\small\sffamily (2) Assign the result to a variable and start writing code for further operations:}
\begin{equation*}
\begin{array}{l}
\kvd{let}\,\ident{shadow}=\ident{image}.\ident{load}(\str{shadow.png}).\ident{greyScale}().\ident{blur}(\num{8})\\
\ident{shadow}.\ident{combine}
\end{array}
\end{equation*}

\vspace{0.5em}\hspace{1.5em}{\small\sffamily (3) Finish code to combine two images and then change parameter of combine from 20 to 80:}
\begin{equation*}
\begin{array}{l}
\kvd{let}\,\ident{shadow}=\ident{image}.\ident{load}(\str{shadow.png}).\ident{greyScale}().\ident{blur}(\num{8})\\
\ident{shadow}.\ident{combine}(\ident{image}.\ident{load}(\str{pope.png}), \num{20})
\end{array}
\end{equation*}

\vspace{0.5em}\hspace{1.5em}{\small\sffamily (4) Extract the parameter of combine to a let bound variable:}
\begin{equation*}
\begin{array}{l}
\kvd{let}\,\ident{ratio} = \num{80} \\
\kvd{let}\,\ident{shadow}=\ident{image}.\ident{load}(\str{shadow.png}).\ident{greyScale}().\ident{blur}(\num{8})\\
\ident{shadow}.\ident{combine}(\ident{image}.\ident{load}(\str{pope.png}), \ident{ratio})
\end{array}
\end{equation*}

\caption{Code edit operations that are used in the experimental evaluation}
\label{fig:image-edits}
\end{figure}

% --------------------------------------------------------------------------------------------------

\begin{figure}[b]
\vspace{-0.5em}
\includegraphics[scale=0.425]{drawing.png}
\caption{Time required to recompute the results of a sample program after individual tokens of
  the program are added or modified for three different evaluations strategies.}
\label{fig:drawing}
\vspace{-0.5em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsubsection{Code edit operations and methodology}

To avoid clutter when visualizing the performance, we update the preview after complete tokens are
added (such as identifier, number, dot or left parenthesis) rather than after individual keystrokes.
Figure~\ref{fig:image-edits} shows the sequence of code edit operations that we use to measure
the delays in updating a live preview. We first enter an expression to load, greyscale and blur
an image (1) then introduce let binding (2) and add more operations (3). Finally, we extract
one of the parameters into a variable (4). Most of the operations are simply adding code, but
there are two cases where we modify existing code and change value of a parameter for \ident{blur}
and \ident{combine} immediately after (1) and (3), respectively.

We implement the algorithm described in Sections~\ref{sec:formal} and \ref{sec:previews} in a
simple web-based environment that allows the user to modify code and explicitly trigger
recomputation. It then measures time needed to recompute values for the whole program and
displays the resulting image. If the parsing fails, e.g.~because of an unclosed parenthesis,
previews are not updated and we record only the time taken by parsing attempt. We compare the
delays of three different evaluation strategies:

\begin{itemize}[itemsep=3pt]
\item \emph{Call-by-value.} Following the semantics in Section~\ref{sec:calculus-semantics},
  all sub-expressions are fully evaluated before an expression is evaluated. In this case, work may
  be done even if the evaluation results in an error. For example, we parse
  $\ident{image}.\ident{load}(\str{shadow.png}).\ident{blur}$ as member access with no arguments.
  The evaluation loads the image, but then fails because blur requires one argument.

\item \emph{Lazy.} To address the wastefulness of call-by-value strategy discussed above, we
  simulate lazy evaluation by implementing a version of the image processing library where
  operations build a delayed computation and only evaluate it when rendering an image. Using
  this strategy, failing computations do not perform unnecessary work.

\item \emph{Live.} Finally, the live strategy uses the algorithm described in
  Sections~\ref{sec:formal} and \ref{sec:previews}. The cache is empty at the beginning of the
  experiment and we update it after each token is added. This is the only strategy that does
  not start afresh after reparsing code.
\end{itemize}

\subsubsection{Efficiency evaluation}
The experimental environment is implemented in F\# and compiled to JavaScript using the Fable
compiler. We run the experiments in Firefox (version 64.0.2, 32bit) on Windows 10
(1809, 64bit) on a computer with Intel Core i7-7660U CPU and 16Gb RAM.

Figure~\ref{fig:drawing} shows times needed to recompute previews after individual tokens
of the program are added, deleted or modified, according to the script in
Figure~\ref{fig:image-edits}, resulting in 38 measurements for each of the 3
evaluation strategies. We mark a number of notable points in the chart:

\begin{enumerate}[(a)]
\item Loading image for the first time incurs small extra overhead in the live strategy.
\item Greyscaling using the live strategy does not need to re-load the image.
\item Accessing the blur member without arguments causes delay for call-by-value strategy.
\item When varying the parameter of blur, the live strategy reuses previously greyscaled image.
\item Introducing let binding does not cause recomputation when using live strategy.
\item As in (c), accessing combine member without valud argument only affects call-by-value.
\item Varying parameter of combine in live strategy does not recompute blur and is much faster.
\item Introducing let binding, again, causes full recomputation for lazy can call-by-value.
\end{enumerate}

% --------------------------------------------------------------------------------------------------

\begin{figure}
\noindent
\includegraphics[scale=0.48]{hist-all.png}
\includegraphics[scale=0.48]{hist-slow.png}
\caption{Histogram showing the distribution of delays incurred when updating previews.
  We show a histogram computed from all delays (left) and only from delays larger
  than 15ms (right).}
\label{fig:drawing-hist}
\end{figure}

% --------------------------------------------------------------------------------------------------

\noindent
A summarized view of the delays is provided in Figure~\ref{fig:drawing-hist}, which shows
histograms illustrating the distribution of delays for each of the three evaluation methods.
A large proportion of delays is very small (less than 15ms) because the parser used in our
experimental environment often fails (e.g.~for unclosed parentheses). The histogram
on the right summarizes only delays for edit operations where the delay for at least one of
the strategies was over 15ms. A more robust parser would be able to recover and the delays
for call-by-value and lazy strategies would be even more significant.

\subsubsection{Summary of results}
The purpose of our empirical is not to exactly assess the overhead of our implementation
of the live evaluation strategy algorithm. Instead, our goal is to
illustrate how often can previously evaluated results be reused and the impact this has when
writing code. The experiment presented in this section is small-scale, but it is sufficient
to illustrate the main point.

When recomputing results after every edit operation
using the \emph{call-by-value} strategy, the time needed to update the results grows
continually. The \emph{lazy} strategy removes the overhead for programs that fail to evaluate, but
keeps the same trend. Using our \emph{live} strategy, the computation can reuse values computed
previously and, as a result, expensive operations (such as (d) and (g) in Figure~\ref{fig:drawing})
are significantly faster, because they do not need to recompute operations done previously when
writing the code. As shown in Figure~\ref{fig:drawing-hist}, there are almost no very expensive
operations (taking over 1 second) in the \emph{live} strategy in contrast to several in the
other two strategies.

% --------------------------------------------------------------------------------------------------

\newpage

\section{Case study / implementation}
\label{sec:case}

http://gallery.thegamma.net/75/gender-pay-gap
http://gallery.thegamma.net/73/libraries
http://gallery.thegamma.net/47/unemployment-in-italy
http://gallery.thegamma.net/44/classification-of-the-functions-of-government-cofog
http://gallery.thegamma.net/37/top-10-government-departments-by-201516-expenditure

% ==================================================================================================

\section{Type checking}
\label{sec:types}

Evaluating live previews can be an expensive operations, so being able to cache partial previews
is a must for a live coding environment. Type checking is typically fast, so the main focus of
this paper is on live previews. However, asynchronous type providers in The Gamma (Section~\ref{sec:types-providers})
can make type checking time consuming, and so we use the dependency graph also for type checking
(Section~\ref{sec:types-graph}). Type checking lambda functions (Section~\ref{sec:types-funs})
requires a slight extension of the model discussed in Section~\ref{sec:formal}.

% --------------------------------------------------------------------------------------------------

\subsection{Asynchronously provided types}
\label{sec:types-providers}

Data available in The Gamma can be defined using several kinds of type providers. The type provider
used in Figure~\ref{fig:thegamma} as asynchronous \cite{async}. It downloads the sample URL and generates
types based on the contents of the web page. The parameter to \ident{web.scrape} is a static
parameter and is evaluated during type-checking. We omit details in this paper, but we note this
works similarly to F\# type providers \cite{providers-fsharp}.

Type providers can also be implemented as REST services \cite{rest} to allow anyone implement a data source
in the language of their choice. In this case, each member of a call-chain returns a type that is
generated based on the result of an HTTP request. For example, when the user types \ident{worldbank}
(to access information about countries), the type provider makes a request to
\url{http://thegamma-services.azurewebsites.net/worldbank}, which returns two members:
%
\begin{equation*}
\begin{array}{l}
[~\{\rstr{name}\!:\str{byYear},\rstr{returns}\!:\\
~\quad \{\rstr{kind}\!:\str{nested},\rstr{endpoint}\!:\str{/pickYear}\}\}\\
\hspace{0.55em}\{\rstr{name}\!:\str{byCountry},\rstr{returns}\!:\\
~\quad \{\rstr{kind}\!:\str{nested},\rstr{endpoint}\!:\str{/pickCountry}\}\}~]
\end{array}
\end{equation*}
%
This indicates that \ident{worldbank} has members \ident{byYear} and \ident{byCountry}.
If the user types \ident{worldbank.byCountry}, a request is made to the specified URL
\url{http://thegamma-services.azurewebsites.net/worldbank/pickCountry}:
%
\begin{equation*}
\begin{array}{l}
[~\{\rstr{name}\!:\str{Andorra},\rstr{trace}\!:[\str{"country=AR"}], \\
\quad \rstr{returns}\!:\{\rstr{kind}\!:\str{nested},\rstr{endpoint}\!:\str{/pickTopic}\}\}\\
\hspace{0.55em}\{\rstr{name}\!:\str{Afghanistan},\rstr{trace}\!:[\str{"country=AF"}],\\
\quad \rstr{returns}\!:\{\rstr{kind}\!:\str{nested},\rstr{endpoint}\!:\str{/pickTopic}\}\},\,..]
\end{array}
\end{equation*}
%
This returns a list of countries which can then be accessed as members via
\ident{worldbank.byCountry.Andorra}, etc.

This is one reason for why type checking in The Gamma can be time consuming. Other
type providers may perform other more computationally intensive work to provide types and so
it is desirable to reuse type-checking results during live coding. The rest of this section
shows how this is done using the dependency graph discussed in Section~\ref{sec:formal}.

\begin{figure}[!b]
\vspace{-0.5em}
\begin{equation*}
\xymatrix{
&\bnd{val}(o)\\
&\bnd{mem}(m, s_0) \ar[u]_{\blbl{arg}(0)} \ar[dl]^{\blbl{arg}(1)} \\
\bnd{fun}(x, s_2) \ar@/^/[uur]^{\blbl{callsite}(m, 1)} \ar[rr]^{\blbl{body}} && \bnd{var}(x, s_1) \ar@/_/[uul]_{\blbl{callsite}(m, 1)}
}
\end{equation*}
\caption{Dependency graph for $o.m(\lambda x\rightarrow x)$}
\label{fig:graph-func}
\end{figure}

% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
\vspace{-0.5em}
\begin{equation*}
\begin{array}{ll}
\ident{bind-expr}_{\Gamma, \Delta, c}(e_0.m(e_1, \ldots, e_n)) = &(2b)\\
\qquad \bndclr{v}, (\{\bndclr{v}\} \cup V_0 \cup \ldots \cup V_n, E \cup E_0 \cup \ldots \cup E_n)\\
\quad \textnormal{when}~\bndclr{v_0}, (V_0, E_0) = \ident{bind-expr}_{\Gamma, \Delta, \bot}(e_0)\\
\quad \textnormal{and}~c_i = (\bndclr{v_0}, \blbl{callsite}(m,i))\hspace{4.8em} (i \in 1\ldots n)\\
\quad \textnormal{and}~\bndclr{v_i}, (V_i, E_i) = \ident{bind-expr}_{\Gamma, \Delta, c_i}(e_i)\qquad (i\in 1\ldots n)\\
\quad \textnormal{and}~(\bknd{mem}(m),[(\bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v_n}, \blbl{arg}(n))]) \notin \ident{dom}(\Delta)\hspace{-200em}.\\
\quad \textnormal{let}~\bndclr{v} = \bnd{mem}(m, s), s~\textnormal{fresh}\\
\quad \textnormal{let}~E = \{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v},\bndclr{v_n}, \blbl{arg}(n)) \}
\end{array}
\qquad\qquad
\begin{array}{ll}
\ident{bind-expr}_{\Gamma, \Delta, (\bndclr{v_c}, \blblclr{l_c} )}(\lambda x \rightarrow e) = \bndclr{v}, (\{\bndclr{v}\} \cup V_0, E \cup E_0)&(7b)\\
\quad \textnormal{when}~(\bknd{var}(x),[(\bndclr{v_c}, \blblclr{l_c} )])\notin \ident{dom}(\Delta)\\
\quad \textnormal{let}~\bndclr{v_x} = \bnd{var}(x, s_x), s_x~\textnormal{fresh}\\
\quad \textnormal{and}~\Gamma_1 = \Gamma \cup \{ x, \bndclr{v_x} \}\\
\quad \textnormal{and}~\bndclr{v_0}, (V_0, E_0) = \ident{bind-expr}_{\Gamma_1, \Delta, \bot}(e)\\
\quad \textnormal{when}~(\bknd{fun}(x),[(\bndclr{v_0}, \blbl{body}), (\bndclr{v_c}, \blblclr{l_c} )])\notin \ident{dom}(\Delta)\\
\quad \textnormal{let}~\bndclr{v} = \bnd{fun}(x, s_f), s_f~\textnormal{fresh}\\
\quad \textnormal{let}~E = \{ (\bndclr{v},\bndclr{v_0},\blbl{body}), (\bndclr{v},\bndclr{v_c},\blblclr{l_c}), (\bndclr{v_x},\bndclr{v_c},\blblclr{l_c}) \}
\\[0.75em]
\end{array}
\end{equation*}
\vspace{-0.5em}
\caption{Revised binding rules, tracking call sites of function values.}
\label{fig:binding-rules-callsite}
\vspace{-0.5em}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\subsection{Revised binding of functions}
\label{sec:types-funs}

The Gamma script supports lambda functions, but only in a limited way. A function can be passed
as a parameter to a method, which makes type checking of functions easier. For example, consider:
%
\begin{equation*}
\begin{array}{l}
\ident{movies}.\ident{sortBy}(\lambda x \rightarrow x.\ident{getBudget}())
\end{array}
\end{equation*}
%
If \ident{movies} is a collection of \ident{Movie} objects, the type of the lambda function must be
$\ident{Movie}\rightarrow\ident{bool}$ and so the type of $x$ is \ident{Movie}. This is similar to
type checking of lambda functions in C\# \cite{csharp}, where type is also inferred from the context (or has
to be specified explicitly).

We do not currently allow lambda functions as stand-alone let-bound
values. This could be done by requiring explicit types, or introducing polymorphism, but it was not
necessary for the limited domain of non-expert data exploration.

\paragraph{Dependency graph for functions.}
In the binding process specified in Section~\ref{sec:formal}, a variable is a leaf of the dependency
graph. In the revised model, it depends on the context in which it appears. A new edge labeled
$\blbl{callsite}(m, i)$ indicates that the source node is the input variable of a function
passed as the $i^\textnormal{th}$ argument to the $m$ member of the expression represented by the
target node. A node representing function is linked to the call site using the same edge.

Figure~\ref{fig:graph-func} shows the result of binding $o.m(\lambda x\rightarrow x)$. Both
$\bnd{fun}(x, s_2)$ and $\bnd{var}(x, s_1)$ now depend on the node representing $o$. The new
$\blbl{callsite}$ edge makes it possible to type-check function and variable nodes just using their
dependencies. As before, the member invocation $\bnd{mem}(m, s_0)$
depends on the instance using $\blbl{arg}(0)$ and on its argument using $\blbl{arg}(1)$.

% --------------------------------------------------------------------------------------------------

\begin{figure*}
\vspace{0.5em}
\begin{equation*}
\begin{array}{l}
\qquad\inference[\rname{val}~]
  {\Sigma(n) = \alpha}
  {\bnd{val}(n) \vdash \alpha }
\quad\qquad
\inference[\rname{var}~]
  { (\bnd{var}(x,s), \bndclr{v}, \blbl{callsite}(m, i)) \in E &
    \bndclr{v} \vdash (.., m:(\tau_1, \ldots, \tau_k)\rightarrow \tau,..) & \tau_i=\tau'\rightarrow\tau'' }
  { \bnd{var}(x, s) \vdash \tau' }
\\[2.5em]
\inference[\rname{fun}~]
  { \{(\bnd{fun}(x,s), \bndclr{v_b}, \blbl{body}), (\bnd{var}(x,s), \bndclr{v_c}, \blbl{callsite}(m, i))\} \subseteq E &
    \bndclr{v_c} \vdash (.., m:(\tau_1, \ldots, \tau_k)\rightarrow \tau,..) &
    \tau_i=\tau'\rightarrow\tau'' & \bndclr{v_b} \vdash \tau'' }
  { \bnd{fun}(x, s) \vdash \tau' \rightarrow \tau'' }
\\[2.5em]
\qquad\qquad\quad\inference[\rname{mem}~]
  { \forall i\in\{0\ldots k\}.(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E &
    \bndclr{v_0} \vdash (.., m:(\tau_1, \ldots, \tau_k) \rightarrow \tau, ..)& \bndclr{v_i} \vdash \tau_i }
  { \bnd{mem}(m, s) \vdash \tau }
\\[1em]
\end{array}
\end{equation*}
\caption{Rules that define evaluation of previews over a dependency graph for an expression}
\vspace{0.5em}
\label{fig:tc}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\paragraph{Revised binding process.}
For the revised binding process, we introduce a new edge label $\blbl{callsite}$. Variable nodes
now have dependencies and so we cache them and attach a symbol $s$ to \bnd{var}, so we also
introduce a node kind $\bknd{var}$ as part of a lookup key for $\Delta$.

The \ident{bind-expr} function now has a parameter $c$, in addition to $\Gamma$ and $\Delta$, which
represents the context in which the binding happens. This is either a member invocation (labeled
with instance node $\bndclr{v}$ and \blbl{callsite} label $\blblclr{l}$), or not a member
invocation written as $\bot$. The updated definitions are:
%
\begin{equation*}
\begin{array}{lcll}
\bndclr{v} &\hspace{-0.5em}\in\hspace{-0.5em}&\bnd{val}(n)~|~\bnd{var}(x, s)~|~\bnd{mem}(m, s)~|~\bnd{fun}(x, s)&(\textit{Vertices})\\
\blblclr{l}&\hspace{-0.5em}\in\hspace{-0.5em}&\blbl{body}~|~\blbl{arg}(i)~|~\blbl{callsite}(m,i)&(\textit{Edge labels})\\
\bkndclr{k}&\hspace{-0.5em}\in\hspace{-0.5em}&\bknd{fun}(x)~|~\bknd{mem}(m)~|~\bknd{var}(x)&(\textit{Node kinds})\\
          c&\hspace{-0.5em}\in\hspace{-0.5em}&\bot ~|~(\bndclr{v}, \blblclr{l})&(\textit{Call sites})\\
\end{array}
\end{equation*}
%
The key parts of the revised definition of the \ident{bind-expr} function are shown in Figure~\ref{fig:binding-rules-callsite}.
We now write $\ident{bind-expr}_{\Gamma,\Delta,c}$ where $c$ represents the context in which the
binding occurs. This is set to $\bot$ in all cases, except when binding arguments of a member call.
In (2b), we first recursively bind the instance node using $\bot$ as the context and then
bind all the arguments using $(\bndclr{v_0}, \blbl{callsite}(m, i))$ as the context for $i^{\textnormal{th}}$
argument. The rest is as in case (2) before. The case (1) is updated similarly and is not shown
here for brevity.

When binding a function (7b), we now also store variable nodes in $\Delta$ and so we check if a
variable with the given call site exists. If no, we create a fresh node $\bnd{var}(x, s_x)$.
The node is added to $\Gamma$ as before. At the end, we now also include a call site edge from the
variable node and from the function node in $E$. We omit a similar variant of the case (6).
The remaining cases (3)-(5) are the same, except that \ident{bind-expr} has the additional $c$ parameter
and recursive calls always set it to $\bot$.

Finally, the \ident{update} function in Figure~\ref{fig:loop} also needs to be updated to store the
newly created \bnd{var} nodes. This is done by adding the following single case:

\begin{equation*}
\begin{array}{l}
\Delta_{i}(\bknd{var}(x), [(\bndclr{v},\blbl{callsite}(m,i))]) = \bnd{var}(x, s)\\
\quad\quad \textnormal{for all}~\bnd{var}(x, s) \in V\\
\quad\quad \textnormal{such that}~(\bnd{var}(x, s), \bndclr{v}, \blbl{callsite}(m,i)) \in E
\end{array}
\end{equation*}

% --------------------------------------------------------------------------------------------------

\subsection{Type checking over dependency graphs}
\label{sec:types-graph}

The type system for The Gamma supports a number of primitive types (such as integers and strings)
written as $\alpha$. Composed types include functions and objects with members. Objects are be
provided by type providers, but we omit the details here. Types of object members are written as
$\sigma$ and can have multiple arguments:
%
\begin{equation*}
\begin{array}{lcll}
\tau&\in&\alpha ~|~ \tau \rightarrow \tau ~|~ \{m_1\!:\!\sigma_1, \ldots, m_n\!:\!\sigma_n\} &\quad(\textit{Types})\\
\sigma &\in& (\tau_1, \ldots, \tau_n) \rightarrow \tau &\quad(\textit{Members})\\
\end{array}
\end{equation*}
%
The typing judgements are written in the form $\bnd{v}\vdash \tau$. They are parameterised by the
dependency graph $(V, E)$, but this is not modified during type checking so we keep it implicit
rather than writing e.g.~$\bnd{v}\vdash_{(V,E)} \tau$.

\paragraph{Type checking.}
The typing rules are shown in Figure~\ref{fig:tc}. Types of primitive values $n$ are obtained
using a global lookup table $\Sigma$ \rname{val}. When type checking a member call \rname{mem},
we find its dependencies $\bndclr{v_i}$ and check that the first one (instance) is an object with
the required member $m$. The types of input arguments of the member then need to match the types
of the remaining (non-instance) nodes.

Type checking a function \rname{fun} and a variable \rname{var} is similar. In both cases,
we follow the \blbl{callsite} edge to find the member that accepts the function as an argument.
We obtain the type of the function from the type of the $i^\textnormal{th}$ argument of the
member. We use the input type as the type of variable \rname{var}. For functions, we also check
that the resulting type matches the type of the body \rname{fun}.

\paragraph{Caching results.}
Performing type checking over the dependency graph, rather than over the abstract syntax tree,
enables us to reuse the results of previously type checked parts of a program. As when
caching evaluated previews (Section~\ref{sec:previews}), we build a lookup table mapping graph
nodes to types. When type checking a node, we first check the cache and, only if it is new,
follow the $\vdash$ relation to obtain the type.

As a result, code can be type checked on-the-fly during editing, even when asynchronous type
providers are used, and the programmer gets instant feedback without delays.

% --------------------------------------------------------------------------------------------------

\subsection{Properties of type checking}

As noted in Section~\ref{sec:types}, the focus of this paper is on live previews, but we also
use the method based on reusing nodes in a dependency graph for type checking. We do not discuss
properties of type checking in detail, but we briefly note how the different properties of
live previews extend to corresponding properties of type checking.

\paragraph{Type checking result reuse.} In Section~\ref{sec:evaluation-reuse}, we show that
certain source code edits do not cause the recomputation of previews for the whole expression
or a sub-expression. The edits are given in Figure~\ref{fig:operations}. The proof uses the fact
that the newly bound graph (after code edit) reuses nodes of the previous graph. This implies that
type checking results can be reused in exactly the same way as live previews -- they are also
stored in a lookup table with graph nodes as keys.

\paragraph{Correctness.} The correctness property (Theorem~\ref{thm:correctness}) shows that
graph-based preview evaluation matches direct evaluation of expressions. To show a corresponding
property for type checking, we would need to provide ordinary type system based on the structure
of the expression and prove that the two are equivalent. In our implementation, we only use the
presented graph-based type checking method, so we do not provide an alternate account in this paper.

\paragraph{Determinacy.} The determinacy property (Theorem~\ref{thm:determinacy}) guarantees that
previews can be cached, because evaluating them again, using $\Downarrow$ over an updated graph,
would yield the same result. The same property holds for $\vdash$, meaning that type checking
results can be cached. Although the Theorem~\ref{thm:determinacy} talks explicitly about
$\Downarrow$, it can be easily extended for $\vdash$, because the proof depends on how the graph
is updated using $\ident{update}_{V,E}$ and the binding process.

% ==================================================================================================

\section{Design lessons}
\label{sec:design}

The motivation for the presented work, briefly outlined in Section~\ref{sec:live}, is to build a
simple data exploration environment that would allow non-experts, like data journalists,
transparently work with data. In this paper, we focused on providing live coding experience,
which is one important step toward the goal. However, the language we use is a mix of established
object-oriented (member access) and functional (function values) features with type providers.

If we were to design a new programming language, there are lessons we can learn from the
cases that make type checking and preview evaluation in this paper difficult. This section
briefly considers those.

\paragraph{Functions and type providers.} When using type providers in a nominally-typed language,
the provided types are named, but the names are typically not easy to type \cite{fsdata}. This is
not a problem in typical usage where provided members are accessed via dot. Using the \ident{worldbank}
example from Section~\ref{sec:types-providers}, we can access population of two countries using:
%
\begin{equation*}
\begin{array}{l}
\ident{worldbank.byCountry.\textquotesingle United Kingdom\textquotesingle}.\\
\quad \ident{Indicators.\textquotesingle Population (total)\textquotesingle}\\[0.5em]
\ident{worldbank.byCountry.\textquotesingle Czech Republic\textquotesingle}.\\
\quad \ident{Indicators.\textquotesingle Population (total)\textquotesingle}\hspace{9em}
\end{array}
\end{equation*}
%
However, the fact that the provided types do not have nice names becomes a problem when want to
extract code to access population into a function:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{getPopulation}~c=\\
\quad c.\ident{Indicators.\textquotesingle Population (total)\textquotesingle}\hspace{8.5em}
\end{array}
\end{equation*}
%
Here, the compiler cannot infer the type of $c$ from usage and so we are required to provide a
type annotation using an automatically generated name.

\paragraph{Functions and live previews.}
Providing live previews in a language with ordinary functions suffers from the same problem as
type checking of functions.

Our live preview evaluation, discussed in Section~\ref{sec:previews}, can obtain only a delayed
preview for the body of \ident{getPopulation}. The delayed preview we would obtain in this case
is $\llbracket c.\ident{Indicators}.\ident{\textquotesingle Population (total)\textquotesingle} \rrbracket_{c}$.

If we know the type of $c$, we can provide a user interface that lets the user specify a value
for $c$ (or, more generally, free variables of the preview) and then evaluate the preview, but
it is difficult to provide a meaningful preview automatically.

\paragraph{Wormhole abstractions.}
In data science scripting, we start with a concrete example and then turn code into a reusable
function. This pattern could be supported by the language in a way that makes type checking
and preview evaluation easier. Using an imaginary notation, we could write:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{uk}~=~\ident{worldbank.byCountry.\textquotesingle United Kingdom\textquotesingle}\hspace{1.5em}\\[0.5em]
\kvd{def}~\ident{getPopulation}~=\\
\quad\lbrack\ident{country}\!:\!\ident{uk}\rbrack.\ident{Indicators.\textquotesingle Population (total)\textquotesingle}\\[0.5em]
\ident{getPopulation}~\ident{worldbank.byCountry.China}\\
\ident{getPopulation}~\ident{worldbank.byCountry.India}
\end{array}
\end{equation*}
%
We tentatively call this notation \emph{wormhole} abstraction and we intend to implement it in future prototypes of The Gamma.
The second line is an expression that accesses the population of the UK, using a concrete
data source as the input, but it also defines a named function \ident{getPopulation} that has a
parameter \ident{country}. In a way, we are providing \emph{type annotation} by example, together
with a \emph{value annotation} that can be used for live previews.

This way of constructing abstractions is perhaps more akin to how spreadsheets are used -- we often
write a formula using a concrete cell and then use the ``drag down'' operation to extend it to
other inputs.

% ==================================================================================================

\section{Related and future work}
\label{sec:future}

This paper approaches the problem of live coding environments from a theoretical programming
language perspective with a special focus on tooling for data science. Hence, the related and
future work spans numerous areas.

\paragraph{Design and human-computer interaction.}
TODO: \citet{principle}

From a design perspective, the idea of live programming environments has been popularised by
Bret Victor \cite{learnable}. Active research on novel forms of interaction happens in areas
such as live coded music \cite{beyond,sonic}.
The idea of live previews can be extended to direct manipulation \cite{direct}. The Gamma
provides limited support for directly manipulating data (Section~\ref{sec:live}), but we
intend to explore this direction further.

\paragraph{Data science tooling.}
An essential tool in data science is REPL (read-eval-print-loop) \cite{drscheme}, which is now
widely available. This has been integrated with rich graphical outputs in tools such as Jupyter
notebooks \cite{jupyter,ipython}, but such previews are updated using an explicit command.
Integrating our work with Jupyter to provide instant live previews for R or Python would be
an interesting extension of the presented work.

\paragraph{Live coding and live previews.}
Live previews have been implemented in LightTable \cite{lighttable} and, more recently, in
editors such as Chrome Developer Tools, but neither presents a simple description of their
inner workings. An issue that attracts much attention is keeping state during code edits
\cite{alive,livingit}. This would be an interesting problem if we extended our work to
event-based reactive programming.

\paragraph{Structured editing.}
An alternative approach to ours is to avoid using text editors. Structured editors
\cite{structure-based} allow the user to edit the AST and could, in principle, recompute previews
based on the performed operations, or preview evaluation as in interactive functional programming
\cite{interactive}. A promising direction is using bi-directional lambda calculus~\cite{hazelnut}.
Finally, abandoning text also enables building richer, more human-centric
abstractions as illustrated by Subtext~\cite{subtext}. Our current focus, however, remains
on text-based editors.

\paragraph{Dependency analysis.}
Our use of dependency graphs \cite{dependencies} is first-order. Building dependency graphs
involving function calls using modern compiler methods \cite{optimizing} or program slicing
\cite{slicing} would allow us to deduce possible inputs for functions and use those for
previews rather than changing the language as suggested in Section~\ref{sec:design}. This direction
is worth considering, but it requires more empirical usability testing.

\paragraph{Semantics and partial evaluation.}
The evaluation of previews can be seen as a form of partial evaluation \cite{partial}, done in a
way that allows reuse of results. This can be done implicitly or explicitly in the form of
multi-stage programming \cite{metaml}. Both can provide useful perspective for formally analysing
how previews are evaluated. Semantically, the evaluation of previews can be seen as a modality
\cite{modal} and delayed previews are linked to contextual modal type theory \cite{cmtt}, which,
in turn, can be understood in terms of comonads \cite{cmtt-denotation}. This provides an intriguing
direction for rigorous analysis of the presented system.

% ==================================================================================================

\section{TODO}

TBD: Define live preview somewhere

TBD: In section about dependency graphs, include a subsection discussing how this relates
to incremental computation (just like "Semantics of delayed previews" links that to CMTT etc.)


\cite{selfadjusting}
\cite{incremental}

Incremental computation

  Self-adjusting computation
  http://www.cs.cmu.edu/~rwh/theses/acar.pdf

  Incremental Computation with Names
  https://www.cs.tufts.edu/~jfoster/papers/oopsla15.pdf
  -> dsl interpreter

  (and other adapton stuff http://adapton.org/)

Type checking

  co-contextual
  http://www.informatik.uni-marburg.de/~seba/publications/cocontextual-type-checking.pdf
  http://drops.dagstuhl.de/opus/volltexte/2017/7262/pdf/LIPIcs-ECOOP-2017-18.pdf

https://dl.acm.org/citation.cfm?id=664109

\section{Summary}
We present The Gamma, a live coding environment for data exploration. The environment
bridges the gap between spreadsheets and scripting -- live previews give users rapid feedback,
while the final result is a fully reproducible script.

In this paper, we focus on the challenge of efficiently providing live previews and type checking
code during editing in a free-form text editor. This is a challenge, because users can perform
arbitrary text transformations and we cannot recompute previews after each edit.

The key trick is to separate the process into fast \emph{binding phase},
which constructs a dependency graph and slower \emph{evaluation phase} and \emph{type checking phase}
that can cache results, using the nodes from the dependency graph created during binding as keys.
This makes it possible to quickly parse updated code, reconstruct dependency graph and compute
preview using previous, partially evaluated, results.

We describe our approach formally, which serves two purposes. First, we aim to provide easy to
use foundations for the growing and important trend of text-based live coding environments.
Second, we explore the properties of our system and prove that our method does not recompute
previews in a number of common cases and, at the same time, the optimisation still produces
correct previews.

\bibliography{paper}

\newpage
\appendix

\section{Appendix}

\subsection{Normalization}
\label{sec:app-normalization}

\begin{theorem}[Normalization]
For all $p$, there exists $n$ and $o_1, \ldots, o_n$ such that $p\rightsquigarrow^{*} o_1;\ldots;o_n$.
\end{theorem}
\begin{proof}
We define $\ident{size}$ of a program in data exploration calculus as follows:
\begin{equation}
\begin{array}{rcl}
\ident{size}(c_1; \ldots; c_n) &=& 1 + \Sigma^{n}_{i=1} \ident{size}(c_i)\\
\ident{size}(\kvd{let}~x=t) &=& 1 + \ident{size}(t)\\
\ident{size}(e_0.m(e_1, \ldots, e_n)) &=& 1 + \Sigma^{n}_{i=0} \ident{size}(e_i)\\
\ident{size}(\lambda x\rightarrow e) &=& 1 + \ident{size}(e)\\
\ident{size}(o) = \ident{size}(x) &=& 1\\
\end{array}
\end{equation}

\noindent
The property holds because, first, both \rname{let} and \rname{external} decrease the \ident{size}
of the program and, second, a program is either fully evaluated, i.e.~$o_1;\ldots;o_n$ for some $n$
or, it can be reduced using one of the reduction rules.
\end{proof}


\subsection{Term preview correctness}
\label{sec:app-correctness}

\begin{theorem}[Term preview correctness]
Given a term $t$ that has no free variables, together with a lookup table $\Delta$ obtained
from any sequence of programs using $\ident{bind-prog}$ (Figure~\ref{fig:binding-rules-prog}) and
$\ident{update}$ (Figure~\ref{fig:loop}), then
let $\bndclr{v}, (V, E) = \ident{bind-expr}_{\emptyset, \Delta}(t)$. If $\bndclr{v}\Downarrow p$
over a graph $(V, E)$ then $p = o$ for some value $o$ and $t \rightsquigarrow^{*} o$.
\end{theorem}

\begin{proof}
First note that, when combining recursively constructed sub-graphs, the \ident{bind-expr} function
adds new nodes and edges leading from those new nodes. Therefore, an evaluation using~$\Downarrow$
over a sub-graph will also be valid over the new graph -- the newly added nodes and edges do not introduce
non-determinism to the rules given in Figure~\ref{fig:eval}.

We prove a more general property showing that for any $e$, its binding
$\bndclr{v}, (V, E) = \ident{bind-expr}_{\emptyset, \Delta}(e)$ and any evaluation context $C$
such that $C[e]\rightsquigarrow o$ for some $o$, one of the following holds:
%
\begin{enumerate}
\item[a.] If $FV(e)\,=\,\emptyset$ then $\bndclr{v} \Downarrow p$ for some $p$ and $C[p] \rightsquigarrow o$
\item[b.] If $FV(e)\neq\emptyset$ then $\bndclr{v} \Downarrow \llbracket e_p \rrbracket_{FV(e)}$ for some $e_p$ and $C[e_p] \rightsquigarrow o$
\end{enumerate}
%
In the first case, $p$ is a value, but it is not always the case that $e \rightsquigarrow^{*} p$,
because $p$ may be lambda function and preview evaluation may reduce sub-expression in the body of
the function. Using a context $C$ in which the value reduces to an object avoids this problem.

The proof of the theorem follows from the more general property. Using a context $C[-]=-$, the
term $t$ reduces $t \rightsquigarrow^{*}t' \rightsquigarrow_\epsilon o$ for some $o$ and the
preview $p$ is a value $o$ because $C[p] = p = o$.
The proof is by induction over the binding process, which follows the structure of the expression:

\vspace{0.75em}\noindent(1) $\ident{bind-expr}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n))$ --
  Here $e = e_0.m(e_1, \ldots, e_n)$, $\bndclr{v_i}$ are graph nodes obtained by induction for
  expressions $e_i$ and $\{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v}, \bndclr{v_n}, \blbl{arg}(n))\} \subseteq E$.
  From lookup inversion Lemma~\ref{thm:lemma-lookup}, $\bndclr{v} = \bnd{mem}(m, s)$ for some $s$.

  If $FV(e)=\emptyset$, then $\bndclr{v_i} \Downarrow p_i$ for $i\in 0\ldots n$ and
  $\bndclr{v}\Downarrow p$ using \rname{mem-val} such that $p_0.m(p_1, \ldots, p_n) \rightsquigarrow p$.
  From induction hypothesis and \emph{compositionality} of external libraries (Definition~\ref{def:external}),
  it holds that for any $C$ such that $C[e_0.m(e_1, \ldots, e_n)] \rightsquigarrow o$ for some $o$
  then also $C[p_0.m(p_1, \ldots, p_n)] \rightsquigarrow C[p] \rightsquigarrow o$.

  If $FV(e)\neq\emptyset$, then $\bndclr{v_i} \Downarrow_\ident{lift} \llbracket e'_i \rrbracket$ for $i\in 0\ldots n$ and
  $\bndclr{v}\Downarrow \llbracket e'_0.m(e'_1, \ldots, e'_n) \rrbracket_{FV(e)}$ using \rname{mem-expr}.
  From induction hypothesis and \emph{compositionality} of external libraries (Definition~\ref{def:external}),
  it holds that for any $C$ such that $C[e_0.m(e_1, \ldots, e_n)] \rightsquigarrow o$ for some $o$
  then also $C[e'_0.m(e'_1, \ldots, e'_n)] \rightsquigarrow o$.

\vspace{0.75em}\noindent(2) $\ident{bind-expr}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n))$ --
  This case is similar to (1), except that the fact that $\bndclr{v} = \bnd{mem}(m, s)$
  holds by construction, rather than using Lemma~\ref{thm:lemma-lookup}.

\vspace{0.75em}\noindent(3) $\ident{bind-expr}_{\Gamma, \Delta}(\lambda x\rightarrow e_b)$ --
  Here $e = \lambda x\rightarrow e_b$, $\bndclr{v_b}$ is the graph node obtained by induction
  for the expression $e_b$ and $(\bndclr{v}, \bndclr{v_b}, \blbl{body}) \in E$.
  From lookup inversion Lemma~\ref{thm:lemma-lookup}, $\bndclr{v} = \bnd{fun}(x, s)$ for some $s$.
  The evaluation can use one of three rules:

  \begin{enumerate}
  \item[i.]
  If $FV(e)=\emptyset$ then $\bndclr{v_b}\Downarrow p_b$ for some $p_b$ and $\bndclr{v}\Downarrow \lambda x\rightarrow p_b$
  using \rname{fun-val}. Let $e'_b=p_b$.

  \item[ii.]
  If $FV(e_b)=\{x\}$ then $\bndclr{v_b}\Downarrow \llbracket e'_b \rrbracket_x$ for some $e'_b$ and
  $\bndclr{v}\Downarrow \lambda x\rightarrow e'_b$ using \rname{fun-bind}.

  \item[iii.]
  Otherwise, $\bndclr{v_b}\Downarrow \llbracket e'_b \rrbracket_{x,\Gamma}$ for some $e'_b$ and
  $\bndclr{v}\Downarrow \llbracket\lambda x\rightarrow e'_b\rrbracket_\Gamma$ using \rname{fun-expr}.
  \end{enumerate}

\noindent
For i.) and ii.) we show that a.) is the case; for iii.) we show that b.) is the case; that is
for any $C$, if $C[\lambda x\rightarrow e_b] \rightsquigarrow o$ then also
$C[\lambda x\rightarrow e'_b] \rightsquigarrow o$. For a given $C$, let $C'[-] = C[\lambda x\rightarrow -]$
and use the induction hypothesis, i.e.~if $C'[e_b] \rightsquigarrow o$ for some $o$ then also $C'[e'_b] \rightsquigarrow o$.

\vspace{0.75em}\noindent(4) $\ident{bind-expr}_{\Gamma, \Delta}(\lambda x\rightarrow e)$  --
  This case is similar to (3), except that the fact that $\bndclr{v} = \bnd{fun}(x, s)$
  holds by construction, rather than using Lemma~\ref{thm:lemma-lookup}.

\vspace{0.75em}\noindent(5) $\ident{bind-expr}_{\Gamma, \Delta}(o)$ -- In this case $e=o$ and $\bndclr{v} = \bnd{val}(o)$
  and $\bnd{val}(o)\Downarrow o$ using \rname{val} and so the case a.) trivially holds.

\vspace{0.75em}\noindent(6) $\ident{bind-expr}_{\Gamma, \Delta}(x)$ -- The initial $\Gamma$ is empty,
  so $x$ must have been added to $\Gamma$ by case (3) or (4). Hence,
  $\bndclr{v}=\bnd{var}(x)$, $\bndclr{v}\Downarrow \llbracket x \rrbracket_{x}$ using \rname{var}
  and so $e_p = e = x$ and the case b.) trivially holds.

\end{proof}

\end{document}
