\documentclass[sigplan,10pt]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage{lineno,hyperref,xcolor}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{xypic}
\usepackage{semantic}
\usepackage{booktabs} 
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage[shortlabels]{enumerate}
\setlist{leftmargin=6mm}

\newcounter{thc}
\newcounter{dfc}

\theoremstyle{plain}
\newtheorem{lem}[thc]{Lemma}
\newtheorem{theorem}[thc]{Theorem}

\theoremstyle{definition}
\newtheorem{definition}[dfc]{Definition}

\acmConference[PL'17]{ACM SIGPLAN Conference on Programming Languages}{January 01--03, 2017}{New York, NY, USA}
\acmYear{2017}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}
\bibliographystyle{ACM-Reference-Format}

\title{Design and implementaiton of a live coding environment for data science}

\author{Tomas Petricek}
\affiliation{
  \institution{The Alan Turing Institute}
  \country{London, United Kingdom}
}
\email{tomas@tomasp.net}


\definecolor{cmtclr}{rgb}{0.0,0.6,0.0}
\definecolor{kvdclr}{rgb}{0.0,0.0,0.6}
\definecolor{numclr}{rgb}{0.0,0.4,0.0}
\definecolor{strclr}{rgb}{0.4,0.3,0.0}
\definecolor{prepclr}{rgb}{0.6,0.0,0.2}
\newcommand{\vect}[1]{\langl #1 \rangl}
\newcommand{\langl}{\begin{picture}(4.5,7)
\put(1.1,2.5){\rotatebox{60}{\line(1,0){5.5}}}
\put(1.1,2.5){\rotatebox{300}{\line(1,0){5.5}}}
\end{picture}}
\newcommand{\rangl}{\begin{picture}(4.5,7)
\put(.9,2.5){\rotatebox{120}{\line(1,0){5.5}}}
\put(.9,2.5){\rotatebox{240}{\line(1,0){5.5}}}
\end{picture}}
\newcommand{\ball}[1]{\FPeval{\result}{clip(201+#1)}\textnormal{\ding{\result}}}
\newcommand{\lsep}{~\,|\,~}
\newcommand{\num}[1]{\textcolor{numclr}{#1}}
\newcommand{\str}[1]{\textnormal{\textcolor{strclr}{\sffamily "#1"}}}
\newcommand{\ident}[1]{\textnormal{\sffamily #1}}
\newcommand{\qident}[1]{\textnormal{\sffamily \guillemotleft #1\guillemotright}}
\newcommand{\dom}{\ident{dom}}
\newcommand{\kvd}[1]{\textnormal{\textcolor{kvdclr}{\sffamily #1}}}

\newcommand{\bndclr}[1]{\textcolor{kvdclr}{#1}}
\newcommand{\bkndclr}[1]{\textcolor{prepclr}{#1}}
\newcommand{\blblclr}[1]{\textcolor{numclr}{#1}}
\newcommand{\bnd}[1]{\textnormal{\textcolor{kvdclr}{\sffamily #1}}}
\newcommand{\bknd}[1]{\textnormal{\textcolor{prepclr}{\sffamily #1}}}
\newcommand{\blbl}[1]{\textnormal{\textcolor{numclr}{\sffamily #1}}}


\begin{document}
\begin{abstract}
Data science can be done by directly manipulating data using spreadsheets, or by writing 
data manipulation scripts using a programming language. The former is error-prone and
does not scale, while the latter requires expert skills. Live coding has the potential to 
bridge this gap and make writing of transparent, reproducible scripts more accessible.

In this paper, we describe a live programming environment for data science that provides instant 
previews and contextual hints, while allowing the user to edit code in an unrestricted way in
a text editor. 

Using a text editor is challenging as any edit can significantly change the structure of code and
fully recomputing previews after every change is too expensive. The presented interpreter partially 
evalautes programs as they are written and reuses results of previous evaluations, making it 
possible to provide instant feedback during development.

We formalise how programs are interpreted and how previews are computed, prove correctness
of the previews and formally specify when can previews be reused. We hope this work will provide
solid and easy to reuse foundations for the emerging trend of live programming environments.
\end{abstract}
\maketitle

% ==================================================================================================
% TODO: Change values from 'n' to 'o' to indicate they are objects and can have members
% ==================================================================================================

\section{Introduction}
One of the aspects that make spreadsheet tools such as Excel more accessible than programming 
environments is their liveness. When you change a value in a cell in Excel, the whole spreadsheet
is updated instantly and you see the new results immediately.

Increasing number of programming environments aim to provide the same live experience for more
standard programming languages, but doing this is not easy. Fully recomputing the whole program after
every single change is inefficient and calculating how a change in source code changes the result
is extremely hard when the editor allows arbitrary manipulation of program text. For example, 
consider the following simple program that gets the release years of 10 most expensive movies 
in a data set \ident{movies}:
%
\begin{equation*}
\begin{array}{l}  
\kvd{let}~\ident{top} =\ident{movies}\\
\quad .\ident{sortBy}(\lambda x \rightarrow x.\ident{getBudget}())\ident{.take}(\num{10})\\
\quad .\ident{map}(\lambda x \rightarrow x.\ident{getReleased()}.\ident{format}(\str{yyyy}))}\\
\end{array}
\end{equation*}
%
A live coding environment shows a preview of the list of dates. Next, assume that the programmer
modifies the code by making the constant $\num{10}$ a variable and changing the date format to see 
the full date:
%
\begin{equation*}
\begin{array}{l}  
\kvd{let}~\ident{count} = \num{10}\\
\kvd{let}~\ident{top} = \ident{movies}\\
\quad .\ident{sortBy}(\lambda x \rightarrow x.\ident{getBudget}())\ident{.take}(\ident{count})\\
\quad \ident{.map}(\lambda x \rightarrow x.\ident{getReleased()}.\ident{format}(\str{dd-mm-yyyy}))}\\
\end{array}
\end{equation*}
%
Ideally, the live coding environment should understand the change, reuse a cached result of the
first two transformations (sorting and taking 10 elements) and only evaluate the last \ident{map}
to differently format the release dates of already computed top 10 movies.

This is not difficult if we represent the program in a structured way and allow the user
to edit code only via primitive operations such as ``extract variable'' (which has
no effect on the result) or ``change constant value'' (which forces recomputation of subsequent
transformations). However, many programmers prefer to edit programs as free form text.

We present the design and implementation of a live coding system that is capable
of reusing previously evaluated expressions as in the example above, yet, is integrated into an
ordinary text editor. Our main contributions are:

\begin{itemize}[itemsep=3pt]
\item We introduce The Gamma (Section~\ref{sec:live}), a simple live coding environment for
  data science. We review its design and implementation and explain how it 
  bridges the gap between programming and spreadsheets.

\item Implementing a live programming system requires different way of thinking about compilers
  and interpreters than the one presented in classic programming language literature. Our 
  formalisation (Section~\ref{sec:formal}) captures the essence of the new perspective.

\item We formalise the evaluation of previews (Section~\ref{sec:previews}) and prove that our
  evaluation and caching mechanism is produces correct previews (Section~\ref{sec:properties-correct}) 
  and can effectively reuse partial results (Section~\ref{sec:properties-reuse}).
  
\item In more speculative conclusions (Section~\ref{sec:design}), we consider alternative
  language designs that would enable further live coding experiences, which are difficult to
  build using our current system.
\end{itemize}

\noindent
We hope the architecture and its formal presentation in this paper can contribute important 
foundations to the growing and important trend of text-based live coding environments.

% --------------------------------------------------------------------------------------------------

\begin{figure*}
\includegraphics[scale=0.21]{wiki.png}
\includegraphics[scale=0.21]{drop.png}
\caption{Scraping 2016 science events. Preview of the Wikipedia source page (left) and live filtering (right).}
\label{fig:thegamma}
\end{figure*}

% ==================================================================================================

\section{Live programming for data exploration}
\label{sec:live}

% https://cacm.acm.org/blogs/blog-cacm/169199-data-science-workflow-overview-and-challenges/fulltext

The Gamma aims to make basic data exploration accessible to non-experts, such as data journalists [X], who
need to use data transparently. As such, we focus on simple scripts that can be written using
tools such as Jupyter notebooks~[X]. Those scripts follow a typical data science workflow [X];
they acquire and reformat data, run a number of analyses using the clean data and then create 
several visualizations.

An important property of data science workflow is that we work with readily available concrete data.
Data scientists load inputs into memory and refer to it in subsequent REPL interactions. They might 
later wrap completed working code into a function (and run on multiple datasets), but 
do not start with functions. We reflect this pattern in our language. 

In this section, we provide a brief overview of The Gamma, a simple live coding environment for
data science. We discuss the language, type providers and the user interface,
before focusing on the algorithms behind live previews in Section~\ref{sec:formal}.

\subsection{The Gamma scripting language}
Figure~\ref{fig:thegamma} shows The Gamma script that scrapes items from a Wikipedia page, 
collects those marked as ``Events'' and filters them. The script illustrates two aspects of the
scripting language used by The Gamma -- its structure and its use of type providers for
dot-driven data exploration.

The scripting language is not intended to be as expressive as, say, R or Python and so it
has a very simple structure -- scripts are a sequence of let-bindings (that obtain or transform 
data) or statements (that produce visualizations). This reflects the fact that we always work
with concrete data and allows us to provide previews.

The most notable limitation of The Gamma is that the scripting language does not support top-level 
functions. This is not a problem for the simple scripts we consider, but it would be an issue for
a general-purpose language. We discuss potential design for functions that would still be based
on working with concrete data in Section~\ref{sec:design}.

\subsection{Dot-driven data exploration}

As ilustrated by the second let binding in Figure~\ref{fig:thegamma}, many opertaions
in The Gamma can be expressed using member access via dot. The underlying mechanism is based
on type providers [X,Y] and the specific type provider used in this example has been described 
elsewhere [X].

Given a data source (scraped Wikipedia page), the type provider generates type with members that allow
a range of transformations of the data such as grouping, sorting and filtering. Some of the members
are based only on the schema (e.g.~\ident{\textquotesingle Item Contains\textquotesingle} or 
\ident{\textquotesingle Drop Heading 2\textquotesingle}), but some may also be generated based
on (a sample of) the dataset (e.g.~the second member in \ident{\textquotesingle Heading 2 
is\textquotesingle.\textquotesingle Events[edit]\textquotesingle}). 

What matters for the purpose of this paper is 
the fact that most operations are expressed via member access matters. First, it means 
that we need to provide live previews for sub-expressions formed by a chain of member accesses.
Second, it means that the result of any member access expression depends on the instance and,
possibly, on the parameters provided for a method call.

\subsection{Direct manipulation and live previews}
The screenshot in Figure~\ref{fig:thegamma} show the editor as implemented in The Gamma. This
includes live previews (discussed in this paper), but also an editor that provides spreadsheet-like
interface for editing the data transformation script.

In our implementation, previews appears below the currently selected let binding.
The preview can be of several types such as web page (left) or data table (right). In this paper,
we describe how we evaluate scripts to obtain the resulting object and we ignore how such objects
are rendered.

The Figure~\ref{fig:thegamma} also shows a special handling of expressions constructed using the
pivot type provider. The editor recognises individual data transformations and provides a simple
user interface for adding and removing transformations and changing their parameters that changes
the source code accordingly. This aspect is not discussed in the present paper. 

% ==================================================================================================

\begin{figure*}
\begin{equation*}
\begin{array}{l}
\xymatrix{
& \bnd{val}(\num{10}) &\qquad\quad& \bnd{val}(\num{15})\\
\bnd{var}(\ident{data}) & 
  \bnd{mem}(\ident{skip},s_0)\ar[l]_{\blbl{arg}(0)} \ar[u]^{\blbl{arg}(1)} && 
  \bnd{mem}(\ident{take},s_1)\ar[ll]_{\blbl{arg}(0)} \ar[u]_{\blbl{arg}(1)}
}\\[5em]
\xymatrix{
&& \bnd{val}(\num{10})\\
\bnd{var}(\ident{data}) & 
  \bnd{mem}(\ident{skip}, s_0)\ar[l]_{\blbl{arg}(0)} \ar@/^/[ru]^{\blbl{arg}(1)} && 
  \bnd{mem}(\ident{take}, s_2)\ar[ll]_{\blbl{arg}(0)} \ar@/_/[lu]_{\blbl{arg}(1)}
}
\end{array}\qquad
\begin{array}{l}
\textnormal{a.) The first graph is constructed from}\\
\textnormal{the following initial expression:}\\[0.5em]
\quad\kvd{let}~x = \num{15}~\kvd{in}\\
\quad\ident{data.skip}(\num{10}).\ident{take}(x)\\
\\
\textnormal{b.) The second diagram shows the updated graph}\\
\textnormal{after the programmer changes $x$ to $10$:}\\[0.5em]
\quad\kvd{let}~x = \num{10}~\kvd{in}\\
\quad\ident{data.skip}(\num{10}).\ident{take}(x)
\end{array}
\end{equation*}
\caption{Dependency graphs formed by two steps of the live programming process. }
\label{fig:dep-graph}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\newpage


\section{Formalising live coding environment}
\label{sec:formal}

In this section, we present a formalisation of a live coding environment for a small,
expression-based programming language that supports \kvd{let} binding, member invocations
and $\lambda$ abstractions. This is the necessary minimum for data exploration as described
in the previous section.  

It excludes constructs such as a mechanism for defining new objects as we assume that those
are imported from the context through a mechanims such as type providers.
%
\begin{equation*}
\begin{array}{lcl}
e &=& \kvd{let}~x = e~\kvd{in}~e ~|~ \lambda x\rightarrow e ~|~ e.m(e, \ldots, e) ~|~ x ~|~ n
\end{array}
\end{equation*}
%
Here, $m$ ranges over member names, $x$ over variables and $n$ over primitive values such as 
numbers. Function values can be passed as arguments to methods (provided by a type provider), but 
for the purpose of this paper, we do not need to be able to invoke them directly.

\paragraph{The problem with functions.}
In the context of live programming, \kvd{let} binding and member access are unproblematic.
We can evaluate them and provide live preview for both of them, including all their sub-expressions.
Function values are more problematic, because their sub-expressions cannot be evaluated. For example:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{page} = \lambda x \rightarrow \ident{movies}.\ident{skip}(x*\num{10}).\ident{take}(\num{10})
\end{array}
\end{equation*}
%
We can provide live preview for the \ident{movies} sub-expression, but not for 
$\ident{movies}.\ident{skip}(x*\num{10})$ because we cannot obtain the value of $x$ without
running the rest of the program and analysing how the function is called later.

The method described in this paper does not provide live preview for sub-expressions that
contain free variables (which are not global objects provided by a type provider), but we
describe possible ways of doing so in Section~X and more speculative design of live coding 
friendly fucntions in Section~Y.

% --------------------------------------------------------------------------------------------------

\subsection{Maintaining dependency graph}
\label{sec:formal-deps}

The key idea behind our implementation is to maintain a dependency graph with nodes 
representing individual operations of the computation that can be partially evaluated
to obtain a preview. Each time the program text is modified, we parse it afresh (using an
error-recovering parser) and bind the abstract syntax tree to the dependency graph.

We remember the previously created nodes of the graph. When binding a new expression to
the graph, we reuse previously created nodes that have the same dependencies. For
expressions that have a new structure, we create new nodes (using a fresh symbol to 
identify them). 

The nodes of the graph serve as unique keys into a lookup table with previously
evaluated operations of the computation. When a preview is requested, we use the node
bound to the expression to find a preview, or evaluate it by first forcing the evaluation 
of all parents in the dependency graph.


% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
\vspace{-0.5em}
\begin{equation*}
\begin{array}{ll}
\ident{bind}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n)) = &(1)~~\\ 
\qquad \bndclr{v}, (\{\bndclr{v}\} \cup V_0 \cup \ldots \cup V_n, E \cup E_0 \cup \ldots \cup E_n)\\
\quad \textnormal{when}~\bndclr{v_i}, (V_i, E_i) = \ident{bind}_{\Gamma, \Delta}(e_i)\\
\quad \textnormal{and}~\bndclr{v} = \Delta(\bknd{mem}(m),[(\bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v_n}, \blbl{arg}(n))])\\
\quad \textnormal{let}~E = \{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v}, \bndclr{v_n}, \blbl{arg}(n))\}
\\[0.75em]
\ident{bind}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n)) = &(2)\\ 
\qquad \bndclr{v}, (\{\bndclr{v}\} \cup V_0 \cup \ldots \cup V_n, E \cup E_0 \cup \ldots \cup E_n)\\
\quad \textnormal{when}~\bndclr{v_i}, (V_i, E_i) = \ident{bind}_{\Gamma, \Delta}(e_i)\\
\quad \textnormal{and}~(\bknd{mem}(m),[(\bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v_n}, \blbl{arg}(n))]) \notin \ident{dom}(\Delta)\hspace{-200em}.\\
\quad \textnormal{let}~\bndclr{v} = \bnd{mem}(m, s), s~\textnormal{fresh}\\
\quad \textnormal{let}~E = \{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v},\bndclr{v_n}, \blbl{arg}(n)) \}
\\[0.75em]
\ident{bind}_{\Gamma, \Delta}(\kvd{let}~x=e_1~\kvd{in}~e_2) = \bndclr{v}, (\{\bndclr{v}\} \cup V \cup V_1, E \cup E_1)&(3)\\
\quad \textnormal{let}~\bndclr{v_1}, (V_1,E_1) = \ident{bind}_{\Gamma,\Delta}(e_1)\\
\quad \textnormal{let}~\Gamma_1 = \Gamma \cup \{(x,\bndclr{v_1})\} \\
\quad \textnormal{let}~\bndclr{v}, (V, E) = \ident{bind}_{\Gamma_1, \Delta}(e_2)
\end{array}
\begin{array}{ll}
\ident{bind}_{\Gamma, \Delta}(n) = \bnd{val}(n), (\{ \bnd{val}(n) \}, \emptyset) }&(4)
\\[0.75em]
\ident{bind}_{\Gamma, \Delta}(x) = \bndclr{v}, (\{ \bndclr{v} \}, \emptyset)\quad \textnormal{when}~\bndclr{v} = \Gamma(x)&(5)
\\[1em]
\ident{bind}_{\Gamma, \Delta}(\lambda x \rightarrow e) = \bndclr{v}, (\{\bndclr{v}\} \cup V, \{e\} \cup E)&(6)\\
\quad \textnormal{when}~\Gamma_1 = \Gamma \cup \{ x, \bnd{var}(x) \}\\
\quad \textnormal{and}~\bndclr{v_0}, (V, E) = \ident{bind}_{\Gamma_1, \Delta}(e)\\
\quad \textnormal{and}~\bndclr{v} = \Delta(\bknd{fun}(x),[(\bndclr{v_0}, \blbl{body})])\\
\quad \textnormal{let}~e = (\bndclr{v}, \bndclr{v_0}, \blbl{body}) 
\\[1em]
\ident{bind}_{\Gamma, \Delta}(\lambda x \rightarrow e) = \bndclr{v}, (\{\bndclr{v}\} \cup V, \{e\} \cup E)&(7)\\
\quad \textnormal{when}~\Gamma_1 = \Gamma \cup \{ x, \bnd{var}(x) \}\\
\quad \textnormal{and}~\bndclr{v_0}, (V, E) = \ident{bind}_{\Gamma_1, \Delta}(e)\\
\quad \textnormal{and}~(\bknd{fun}(x),[(\bndclr{v_0}, \blbl{body})])\notin \ident{dom}(\Delta)\\
\quad \textnormal{let}~\bndclr{v} = \bnd{fun}(s, x), s~\textnormal{fresh}\\
\quad \textnormal{let}~e = (\bndclr{v},\bndclr{v_0},\blbl{body}) 
\\[0.5em]
\end{array}
\end{equation*}
\vspace{-0.5em}
\caption{Rules of the binding process, which constructs a dependency graph for an expression.}
\label{fig:binding-rules}
\end{figure*}

% --------------------------------------------------------------------------------------------------
\paragraph{Elements of the graph.} The nodes of the graph represent individual operations
to be computed. In our design, the nodes themselves are used as keys, so we attach a unique 
\emph{symbol} to some of the nodes. That way, we can create two unique nodes representing, 
for example, access to a member named \ident{take} which differ in their dependencies.

Furthermore, the graph edges are labelled with labels indicating the kind of dependency. For
a method call, the labels are ``first argument'', ``second argument'' and so on. Formally:
%
\begin{equation*}
\begin{array}{rcll}
s&\hspace{-0.25em}\in\hspace{-0.25em}& \textit{Symbol}\\
i&\hspace{-0.25em}\in\hspace{-0.25em}& \textit{Integer}\\
n&\hspace{-0.25em}\in\hspace{-0.25em}& \textit{Primitive values}\\
x&\hspace{-0.25em}\in\hspace{-0.25em}& \textit{Variable names}\\
m&\hspace{-0.25em}\in\hspace{-0.25em}& \textit{Member names}\\[0.5em]
\bndclr{v}&\hspace{-0.25em}\in\hspace{-0.25em}&\bnd{val}(n)~|~\bnd{var}(x)~|~\bnd{mem}(m, s)~|~\bnd{fun}(x, s)&(\textit{Vertices})\\
\blblclr{l}&\hspace{-0.25em}\in\hspace{-0.25em}&\blbl{body}~|~\blbl{arg}(i)&(\textit{Edge labels})\\
\end{array}
\end{equation*}
%
The \bnd{val} node represents a primitive value and contains the value itself. Two occurences
of $\num{10}$ in the source code will be represented by the same node. Member access \bnd{mem}
contains the member name, together with a unique symbol -- two member access nodes with different 
dependencies will contain a different symbol. Dependencies of member access are labelled with 
\blbl{arg} indicating the index of the argument (the instance has index $0$ and arguments 
start with $1$).

Finally, nodes \bnd{fun} and \bnd{var} represent function values and variables bound by $\lambda$ 
abstraction. For simplicity, we use variable names rather than de Bruijn indices and so 
renaming a bound variable foces recomputation.

\paragraph{Example graph.} Figure~\ref{fig:dep-graph} illustrates how we construct and update the 
dependency graph. Node representing $\ident{take}(x)$ depends on the argument -- the
number $\num{15}$ -- and the instance, which is a node representing $\ident{skip}(\num{10})$.
This, in turn, depends on the instance \ident{data} and the number $\num{10}$. Note that variables
bound via \kvd{let} binding such as $x$ do not appear as $\bnd{var}$ nodes. The node using it
depends directly on the node representing the result of the expression that is assigned to $x$.

After changing the value of $x$, we create a new graph. The dependencies of the node 
$\bnd{mem}(\ident{skip}, s_0)$ are unchanged and so the node is reused. This means that this
part of the program is not recomputed. The $\blbl{arg}(1)$ dependency of the \ident{take} call 
changed and so we create a node $\bnd{mem}(\ident{skip}, s_2)$ with a new fresh symbol $s_2$.
The preview for this node is then recomputed as needed using the already known values of its
dependencies.

% --------------------------------------------------------------------------------------------------

\paragraph{Reusing graph nodes.} The binding process takes an expression and constructs a 
dependency graph, reusing existing nodes when possible. For this, we keep a lookup table 
of member access and function value nodes. The key is formed by a node kind (for 
disambiguation) together with a list of dependencies. A node kind is a member access or a function:
%
\begin{equation*}
\begin{array}{lcll}
\bkndclr{k}&\in&\bknd{fun}(x)~|~\bknd{mem}(m)&\qquad(\textit{Node  kinds})
\end{array}
\end{equation*}
%
Given a lookup table $\Delta$, we write $\Delta(\bkndclr{k}, [(\bndclr{n_1},\blblclr{l_1}), \ldots,
(\bndclr{v_n},\blblclr{l_n})])$ to perform a lookup for a node of a kind $\bkndclr{k}$ that has dependencies
$\bndclr{v_1}, \ldots, \bndclr{v_n}$ labelled with labels $\blblclr{l_1}, \ldots, \blblclr{l_n}$.

For example, when creating the graph in Figure~\ref{fig:dep-graph} (b), we perform the following
lookup for the \ident{skip} member access:
%
\[ \Delta(\bknd{mem}(\ident{skip}), [(\bnd{var}(\ident{data}),\blbl{arg}(0)), (\bnd{val}(\num{10}), \blbl{arg}(1))]) \]
%
The lookup returns the node $\bnd{mem}(\ident{skip}, s_0)$ known from the previous step. We then perform
the following lookup for the \ident{take} member access:
%
\[ \Delta(\bknd{mem}(\ident{take}), [(\bnd{mem}(\ident{skip}, s_0),\blbl{arg}(0)), (\bnd{val}(\num{10}), \blbl{arg}(1))]) \]
%
In the previous graph, the argument of \ident{take} was $\num{15}$ rather than $\num{10}$ and so
this lookup fails. We then construct a new node $\bnd{mem}(\ident{take}, s_2)$ using a fresh
symbol $s_2$.

% --------------------------------------------------------------------------------------------------

\subsection{Binding an expressions to a graph}
\label{sec:formal-bind}

When constructing the dependency graph, our implementation annotates the nodes of the 
abstract syntax tree with the nodes of the dependency graph, forming a mapping
$e \rightarrow \bndclr{v}$. For this reason, we call the process \emph{binding}.

The process of binding is defined by the rules in Figure~\ref{fig:binding-rules}.
The \ident{bind} function is annotated with a lookup table $\Delta$ discussed in 
Section~\ref{sec:formal-deps} and a variable context $\Gamma$. The variable context 
is a map from variable names to dependency graph nodes and is used for variables bound
using \kvd{let} binding.

When applied on an expression $e$, binding $\ident{bind}_{\Gamma,\Delta}(e)$ returns a
dependency graph $(V, E)$ paired with a node $\bndclr{v}$ corresponding to the expression $e$.
In the graph, $V$ is a set of nodes $\bndclr{v}$ and $E$ is a set of labelled edges
$(\bndclr{v_1}, \bndclr{v_2}, \blblclr{l})$. We attach the label directly to the edge rather than
keeping a separate colouring function as this makes the formalisation simpler.

\paragraph{Binding member access.} In all rules, we recursively bind sub-expressions to get
a dependency graph for each sub-expression and a graph node that represents it. The nodes 
representing sub-expressions are then used as dependencies for lookup into $\Delta$, together
with their labels. When binding a member access, we reuse an existing node if it is defined by 
$\Delta$ (1) or we create a new node containing a fresh symbol when the domain of $\Delta$ does 
not contain a key describing the current member access~(2). 

\paragraph{Binding let binding.} For \kvd{let} binding (3), we first bind the expression $e_1$ assigned
to the variable to obtain a graph node $\bndclr{v_1}$. We then bind the body expression $e_2$,
but using a variable context $\Gamma_1$ that maps the value of the variable to the graph node
$\bndclr{v_1}$. The variable context is used when binding a variable (6) and so all variables 
declared using \kvd{let} binding will be bound to a graph node representing the value assinged 
to the variable. The node bound to the overall \kvd{let} expression is then the graph node bound
to the body expression.

\paragraph{Binding function values.} If a function value uses its argument, we will not be able
to evaluate its body. In this case, the graph node bound to a function will depend on a synthetic
node $\bnd{var}(x)$ that represents the variable with no value. When binding a function, we 
create the synthetic variable and add it to the variable context $\Gamma_1$ before binding the
body. As with member access, the node representing a function may (7) or may not (8) be already 
present in the lookup table.

% --------------------------------------------------------------------------------------------------

\begin{figure}[!b]
\vspace{-0.5em}
\begin{equation*}
\begin{array}{l}
\Delta_{i}(\bknd{mem}(m), [(\bndclr{v_0},\blbl{arg}(0)),\ldots, (\bndclr{v_n},\blbl{arg}(n))]) = \bnd{mem}(m, s)\\
\quad \textnormal{for all}~\bnd{mem}(m, s) \in V\\
\quad \textnormal{such that}~(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E~\textnormal{for}~i\in 0,..,n
\\[0.75em]
\Delta_{i}(\bknd{fun}(x), [(\bndclr{v_1},\blbl{body})]) = \bnd{fun}(x, s)\\
\quad \textnormal{for all}~\bnd{fun}(x, s) \in V\\
\quad \textnormal{such that}~(\bnd{fun}(x, s), \bndclr{v_1}, \blbl{body}) \in E
\\[0.75em]
\Delta_{i}(\bkndclr{v}) = \Delta_{i-1}(\bkndclr{v})\quad \textnormal{(otherwise)}
\end{array}
\end{equation*}
\vspace{-0.5em}
\caption{Updating the node cache after binding a new graph}
\label{fig:loop}
\end{figure}

% --------------------------------------------------------------------------------------------------

\begin{figure*}
\begin{equation*}
\qquad\qquad\quad\begin{array}{l}
\inference[(lift-expr)~]
  {\bndclr{v} \Downarrow \llbracket e \rrbracket_\Gamma}
  {\bndclr{v} \Downarrow_{\ident{lift}} \llbracket e \rrbracket_\Gamma}
\\
\\
\inference[(lift-prev)~]
  {\bndclr{v} \Downarrow p}
  {\bndclr{v} \Downarrow_{\ident{lift}} \llbracket p \rrbracket_\emptyset}
\\
\\
\inference[(val)~]
  {~}
  {\bnd{val}(n) \Downarrow n }
\\
\\
\inference[(var)~]
  {~}
  {\bnd{var}(x) \Downarrow \llbracket x \rrbracket_x}
  \\[0.5em]~
\end{array}
\qquad
\begin{array}{l}
\inference[(fun-val)~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow p }
  { \bnd{fun}(x, s) \Downarrow \lambda x\rightarrow p }
\\
\\
\inference[(fun-bind)~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow \llbracket e \rrbracket_{x} }
  { \bnd{fun}(x, s) \Downarrow \lambda x\rightarrow e }
\\
\\
\inference[(fun-expr)~]
  { (\bnd{fun}(x, s), \bndclr{v}, \blbl{body}) \in E & \bndclr{v} \Downarrow \llbracket e \rrbracket_{x,\Gamma} }
  { \bnd{fun}(x, s) \Downarrow \llbracket \lambda x\rightarrow e \rrbracket_\Gamma }
\\[0.5em]~
\end{array}
\end{equation*}
\begin{equation*}  
\qquad\qquad\begin{array}{l}
\inference[(mem-val)~]
  { \forall i\in\{0\ldots k\}.(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E & \bndclr{v_i} \Downarrow p_i 
    & p_0.m(p_1, \ldots, p_k) \rightsquigarrow p }
  { \bnd{mem}(m, s) \Downarrow p }
\\  
\\
\inference[(mem-expr)~]
  { \forall i\in\{0\ldots k\}.(\bnd{mem}(m, s), \bndclr{v_i}, \blbl{arg}(i)) \in E & \exists j\in\{0\ldots k\}.\bndclr{v_j}\diagup\hspace{-1em}\Downarrow p_j
   & \bndclr{v_i} \Downarrow_{\ident{lift}} \llbracket e_i \rrbracket_{\Gamma_i}  }
  { \bnd{mem}(m, s) \Downarrow \llbracket e_0.m(e_1, \ldots, e_k) \rrbracket_{\Gamma_0,\ldots,\Gamma k} }
\\
\end{array}
\end{equation*}

\caption{Rules that define evaluation of previews over a dependency graph for an expression}  
\label{fig:eval}
\end{figure*}

% --------------------------------------------------------------------------------------------------


\subsection{Edit and rebind loop}

The binding process formalised in Section~\ref{sec:formal-bind} specifies how to update the 
dependency graph after updated program text is parsed. During live coding, this is done 
repeatedly as the programmer edits code. Throughout the process, we maintain a series of 
lookup table states $\Delta_0, \Delta_1, \Delta_2, \ldots$. Initially, the lookup table is 
empty, i.e.~$\Delta_0 = \emptyset$.

At a step $i$, we parse an expression $e_i$ and calculate the new dependency graph and a node
bound to the top-level expression using the previous $\Delta$:
%
\begin{equation*}
\bndclr{v}, (V, E) = \ident{bind}_{\emptyset, \Delta_{i-1}}(e_i)
\end{equation*}
%
The new state of the node cache is then computed by adding newly created nodes from the graph
$(V, E)$ to the previous cache $\Delta_{i-1}$. This is done for function and member nodes that
contain unique symbols as defined in Figure~\ref{fig:loop}. We do not need to cache nodes
representing primitive values and variables as those do not contain symbols and will remain the
same due to the way they are constructed.

% ==================================================================================================

\section{Evaluating previews}
\label{sec:previews}

The mechanism for constructing dependency graphs defined in Section~\ref{sec:formal} makes it
possible to provide live previews when editing code without recomputing the whole program 
each time the source code changes.

The nodes in the dependency graph correspond to individual operations that will be performed
when running the program. When the dependencies of an operation do not change while editing 
code, the subsequent dependency graph will reuse a node used to represent the operation. 

Our live editor keeps a map from graph nodes to live previews, so a new preview only needs to be
computed when a new node appears in the dependency graph (and the user moves the cursor to a 
code location that corresponds to the node). This section describes how previews are evaluated.

\paragraph{Previews and delayed previews.}
As discussed in Section~\ref{sec:formal}, the body of a function cannot be easily evaluated to
a value if it uses the bound variable. We do not attempt to ``guess'' possible arguments and,
instead, provide a full preview only for sub-expressions with free variables bound by a let binding.
For a function body that uses the bound variable, we obtain a \emph{delayed preview}, which is
an expression annotated with a list of variables that need to be provided before the expression
can be evaluated. We use the following notation:
%
\begin{equation*}
\begin{array}{rcll}
p&\hspace{-0.25em}\in\hspace{-0.25em}&n~|~\lambda x\rightarrow e&\quad(\textit{Fully evaluated previews})\\
d&\hspace{-0.25em}\in\hspace{-0.25em}&p~|~\llbracket e \rrbracket_\Gamma&\quad(\textit{Evaluated and delayed previews})\\
\end{array}
\end{equation*}
%
Here, $p$ ranges over fully evaluated values. It can be either a primitive value (such as number,
string or an object) or a function value with no free variables. A possibly delayed preview $d$ 
can then be either evaluated preview $p$ or an expression $e$ that requires variables $\Gamma$.
For simplicity, we use an untyped language and so $\Gamma$ is a list of variables $x_1, \ldots, x_n$.

\paragraph{Evaluation and splicing.}
In this paper, we omit the specifics of the underlying programming langauge and we focus on the
live coding mechanism. However, we assume that the language is equipped with an evaluation 
reduction $e \rightsquigarrow p$ that reduces a closed expression $e$ into a value $p$.

For delayed previews, we construct a delayed expression using splicing. For example, assuming
we have a delayed previews $\llbracket e_0 \rrbracket_x$ and $\llbracket e_1 \rrbracket_y$. 
If we need to invoke a member $m$ on $e_0$ using $e_1$ as an argument, we construct a new 
delayed preview $\llbracket e_0.m(e_1) \rrbracket_{x, y}$. This operation is akin to expression
splicing from meta-programming [X,Y] and can be more formally captured by Contextual Modal Type 
Theory (CMTT) as outlined below.

\paragraph{Evaluation of previews.}
The evaluation of previews is defined in Figure~\ref{fig:eval}. Given a dependency graph $(V, E)$,
we define a relation $\bndclr{v}\Downarrow d$ that evaluates a sub-expression corresponding to 
the node $\bndclr{v}$ to a (possibly delayed) preview $d$. 

The auxiliary relation $\bndclr{v}\Downarrow_{\ident{lift}} d$ always evaluates
to a delayed preview. If the ordinary evaluation returns a delayed preview, so does the auxiliary
relation (\emph{lift-expr}). If the ordinary evaluation returns a value, the value is wrapped
into a delayed preview requiring no variables (\emph{lift-prev}).

Graph node representing a value is evaluated to a value (\emph{val}) and a graph node representing
an unbound variable is reduced to a delayed preview that requires the variable and returns its
value (\emph{var}).

For member access, we distinguish two cases. If all arguments evaluate to values (\emph{member-val}),
then we use the evaluation relation $\rightsquigarrow$, immediately evaluate the member access and 
produce a value. If one of the arguments is delayed (\emph{member-expr}), because the member access 
is in the body of a lambda function, then we produce a delayed member access experession that
requires the union of the variables required by the individual arguments.

Finally, the evaluation of function values is similar, but requires three cases. If the body can 
be reduced to a value with no unbound variables (\emph{fun-val}), we return a lambda function that
returns the value. If the body requires only the bound variable (\emph{fun-bind}), we return a 
lambda function with the delayed preview as the body. If the body requires further variables,
the result is a delayed preview containing a function.

\paragraph{Caching previews.}
For simplicity, the relation $\Downarrow$ in Figure~\ref{fig:eval} does not specify how previews 
are cached and linked to graph nodes. In practice, this is done by maintaining a lookup table
$\bndclr{v} \rightarrow p$ from graph nodes $\bdnclr{v}$ to (possibly delayed) previews $p$.
Whenever the $\Downarrow$ relation is used to obtain a preview for a graph node, we first 
attempt to find an already evaluated preview using the lookup table. If the preview has not
been previously evaluated, we evaluate it and add it to the lookup table.

The evaluated previews can be reused in two ways. First, multiple nodes can 
depend on one sub-graph in a single dependency graph (if the same sub-expression appears
twice in the program). Second, the keys of the lookup table are graph nodes and nodes are 
reused when a new dependency graph is constructed after the user edits the source code.

\paragraph{Semantics of delayed previews.}
The focus of this paper is on the design and implementation of a live coding environment, 
but it is worth noting that the structure of delayed previews is closely linked to the work
on Contextual Modal Type Theory (CMTT) [X] and comonads [Y]. 

In CMTT, $\lbrack \Psi \rbrack A$ denotes that a proposition $A$ is valid in context $\Psi$,
which is closely related to our delayed preivews written as $\llbracket A \rrbracket_\Psi$.
CMTT defines rules for composing context-dependent propositions that would allow us to express
the splicing operation used in (\emph{mem-expr}). In categorical terms, the context-dependent
proposition can be modelled as an indexed comonad [X]. The evaluation of a preview with no 
context dependencies (built implicitly into our evaluation rules) corresponds to the counit
operation of a comonad and would be explicitly written as $\llbracket A \rrbracket_\emptyset \rightarrow A$.

% ==================================================================================================

\section{Properties of preview evaluation}
\label{sec:properties}

The dependency graph makes it possible to cache partial results when evaluating previews. 
The mechanism needs to satisfy two properties.
First, if we evaluate a preview using dependency graph with caching, it should be the same as the
value we would obtain by evaluating the expression directly. Second, the evaluation of previews 
using dependency graphs should -- in some cases -- reuse previously evaluated partial results.
In other words, we show that the mechanism is correct and implements a useful optimization. 

\subsection{Modelling expression evaluation}
In The Gamma language, computations are expressed using
member access, written as $e.m(e_1,\ldots, e_n)$. In this paper, we do not define how member
access evaluates. This has been done elsewhere [X], but more importantly, the evaluation of
previews does not rely on the exact specifics of the evaluation, provided that the language
satisfies certan basic conditions. The following definitions provides the necessary structure 
for discussing correctness of previews.

Partial evaluation may reduce an expression under $\lambda$-abstraction. We do not require that
the reduction of the host language allows this. Instead, we define an extended reduction relation
and use that in the proofs. The host language only needs to compose well with such extended reduction
as captured by the \emph{compositionality} property below. We also require that the language allows
elimination of let bindings.

\begin{definition}[Host language]
Given a relation on expressions $e_1 \rightsquigarrow e_2$ that models evaluation, we define:

\begin{itemize}
\item[--]  
 A \emph{preview evaluation context} (also referred to as \emph{context}):

\vspace{-1.25em}
\begin{equation*}
\begin{array}{lcl}
C[-] &\hspace{-1em}=\hspace{-1em}& \kvd{let}~x = -~\kvd{in}~e ~|~ \kvd{let}~x = e~\kvd{in}~- ~|~ \lambda x\rightarrow - \\
     &&  e_0.m(e_1, \ldots, e_{k-1}, -, e_{k+1}, \ldots e_n)
\end{array}
\end{equation*}

\item[--]  
An extended reduction relation $\rightsquigarrow_\beta$ such that, for any context $C$, 
$C[e_1] \rightsquigarrow_\beta C[e_2]$ whenever $e_1 \rightsquigarrow e_2$.

\item[--]  
Let elimination $\rightsquigarrow_\ident{let}$ such that, using  capture-avoiding substitution,
  $C[\kvd{let}~x=e_1~\kvd{in}~e_2] \rightsquigarrow_\ident{let} C[e_2[x\leftarrow e_1]]$
\end{itemize}

\noindent
We say that $\rightsquigarrow$ is a suitable \emph{host language reduction} if:
\begin{itemize}
\item[--] It satisfies the \emph{compositionality} property, that is if $e \rightsquigarrow e'$ and 
$C[e]\rightsquigarrow_\beta e''$ then also $C[e']\rightsquigarrow_\beta e''$.

\item[--] Let elimination does not affect the result, i.e.~if $e \rightsquigarrow_{\ident{let}} e'$ 
and $e'\rightsquigarrow_\beta e''$ then also $e\rightsquigarrow_\beta e''$ 
\end{itemize}
\end{definition}

\noindent
The host language in The Gamma is a simple call-by-value functional language without side-effects,
and so it satisfies both compositionality and allows let bindings to be eliminated, although the
latter affects the performance. The mechanism for preview evaluation presented here would also 
work for call-by-name languages, but it would suffer from the expected difficulties in the 
presence of side-effects or non-determinism.

\subsection{Correctness of previews}
\label{sec:properties-correct}

First is corrctness (Theorem~\ref{thm:correcntess}) -- no matter how a graph is constructed, when 
we use it to evaluate a preview for an expression, the preview is the same as the value we would 
obtain by evaluating the expression directly. Second is determinacy (Theorem~\ref{thm:determinacy}) --
if we cache a preview for a graph node and update the graph, the preview would still be the same
when evaluated using an updated graph.

This is the correctness and determinacy property discussed in Section~\ref{sec:properties-correct}.

Eliminating let bindings does not change the result in the host language. It also yields the same
dependency graph.

\begin{lem}[Let elimintion]
Given an expression $e_1$ such that $e_1 \rightsquigarrow_\ident{let} e_2$ and a lookup table $\Delta$
then if $\bndclr{v_1}, (V_1, E_1) = \ident{bind}_{\emptyset, \Delta}(e_1)$ and  
$\bndclr{v_2}, (V_2, E_2) = \ident{bind}_{\emptyset, \Delta}(e_2)$ then it holds that
$\bndclr{v_1} = \bndclr{v_2}$ and also $(V_1, E_1) = (V_2, E_2)$.
\end{lem}

This simplifies the correctness proof as we only need to consider expressions not containing
let bindings (if there were let bindings, both the result and the preview would be equivalent
to one that would be obtained if the let bindings were elimninated)

Now, if we have any let-free expression, we show that the preview obtained via the dependency graph
is a value that is the same as the one we'd get by directly evaluating the expression.

xxx

\begin{theorem}[Determinacy]
\label{thm:determinacy}
Downarrow will always evaluate the same, if we add things to a graph in the defined way.
(this means that we can cache)
\end{theorem}


~

~

~

[Only dependency graph matters, not the history and symbols]
[Symbols are effectively hashes of dependencies]

\begin{lemma}
\label{thm:lemma-lookup}
Lemma X - lookup with red mem(m) returns blue mem(m, s)
\end{lemma}

\begin{theorem}[Let-free correctness]
Given an expression $e$ that has no free variables and does not contain let bindings, together
with a lookup table $\Delta$ obtained from any sequence of expressions according to Figure~\ref{fig:loop}
let $\bndclr{v}, (V, E) = \ident{bind}_{\emptyset, \Delta}(e)$. If $\bndclr{v}\Downarrow d$ 
over a graph $(V, E)$ then $d = p$ for some $p$ and $e \rightsquigarrow_\beta p$.
\end{theorem}
\begin{proof}
First note that, when combining recursively constructed sub-graphs, the \ident{bind} operation
adds new nodes and edges leading from those new nodes. Therefore, an evaluation using $\Downarrow$
over a sub-graph will also be valid over the new graph.

Next, we prove a more general property using induction showing that for $e$ such 
that $\bndclr{v}, (V, E) = \ident{bind}_{\emptyset, \Delta}(e)$:
\begin{enumerate}
\item[a.] If $FV(e)\,=\,\emptyset$ then $\bndclr{v} \Downarrow p$ for some $p$ and $e \rightsquigarrow_\beta p$
\item[b.] If $FV(e)\neq\emptyset$ then $\bndclr{v} \Downarrow \llbracket e_p \rrbracket_{FV(e)}$ for some $e_p$ and
  for any evaluation context $C[-]$ such that $FV(C[e_p])=\emptyset$ it holds that if
  $C[e] \rightsquigarrow_\beta C[e_p]$.  
\end{enumerate}

The proof is done by induction over the binding process, which follows the structure 
of the expression $e$ and can be found in Appendix~\ref{sec:app-correctness}.
\end{proof}


\begin{theorem}[Correctness]
\label{thm:correctness}
(Same as let-free version, but using let elimination to say that this works for any expression)
\end{theorem}

\subsection{Reuse of previews}
\label{sec:properties-reuse}


* Inlining let leads to an equivalent dependency graph

* Given two expressions, if we inline lets and they are structurally different, then 
  their dependency graphs are structurally different

Something about how dependency graph bits are reused correctly, i.e. if there is a source code
change that can change the result, the graph will change.

Something about various code edit operations that will not cause recomputation.

% --------------------------------------------------------------------------------------------------

\newpage

\section{Takeaways}
\label{sec:design}

\section{Related and future}
\label{sec:future}

Integrate with Python/R via Jupyter

\newpage

\section*{References}

\bibliography{paper}

\appendix 

\section{Appendix}
\label{sec:app-correctness}

\setcounter{thc}{-1}
\begin{theorem}[Let-free correctness]
Given an expression $e$ that has no free variables and does not contain let bindings, together
with a lookup table $\Delta$ obtained from any sequence of expressions according to Figure~\ref{fig:loop}
let $\bndclr{v}, (V, E) = \ident{bind}_{\emptyset, \Delta}(e)$. If $\bndclr{v}\Downarrow d$ 
over a graph $(V, E)$ then $d = p$ for some $p$ and $e \rightsquigarrow_\beta p$.
\end{theorem}
\begin{proof}
First note that, when combining recursively constructed sub-graphs, the \ident{bind} operation
adds new nodes and edges leading from those new nodes. Therefore, an evaluation using $\Downarrow$
over a sub-graph will also be valid over the new graph.

Next, we prove a more general property using induction showing that for $e$ such 
that $\bndclr{v}, (V, E) = \ident{bind}_{\emptyset, \Delta}(e)$:
\begin{enumerate}
\item[a.] If $FV(e)\,=\,\emptyset$ then $\bndclr{v} \Downarrow p$ for some $p$ and $e \rightsquigarrow_\beta p$
\item[b.] If $FV(e)\neq\emptyset$ then $\bndclr{v} \Downarrow \llbracket e_p \rrbracket_{FV(e)}$ for some $e_p$ and
  for any evaluation context $C[-]$ such that $FV(C[e_p])=\emptyset$ it holds that if
  $C[e] \rightsquigarrow_\beta C[e_p]$.  
\end{enumerate}

The proof is done by induction over the binding process, which follows the structure 
of the expression $e$:

\vspace{0.75em}\noindent(1) $\ident{bind}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n))$ -- 
  Here $e = e_0.m(e_1, \ldots, e_n)$, $\bndclr{v_i}$ are graph nodes obtained by induction for
  expressions $e_i$ and $\{ (\bndclr{v}, \bndclr{v_0}, \blbl{arg}(0)), \ldots, (\bndclr{v}, \bndclr{v_n}, \blbl{arg}(n))\} \subseteq E$
  From Lemma~\ref{thm:lemma-lookup}, $\bndclr{v} = \bnd{mem}(m, s)$ for some $s$.
  
  If $FV(e)=\emptyset$, then $\bndclr{v_i} \Downarrow p_i$ for $i\in 0\ldots n$ and 
  $\bndclr{v}\Downarrow p$ using (\emph{mem-val}) such that $p_0.m(p_1, \ldots, p_n) \rightsquigarrow p$. 
  From induction hypothesis, $e_i \rightsquigarrow_\beta p_i$ and so, using compositionality of $\rightsquigarrow$, 
  $e_0.m(e_1, \ldots, e_n) \rightsquigarrow_\beta p$.
  
  If $FV(e)\neq\emptyset$, then $\bnclr{v_i} \Downarrow_\ident{lift} \llbracket e'_i \rrbracket$ for $i\in 0\ldots n$ and 
  using (\emph{mem-expr}), $\bndclr{v}\Downarrow \llbracket e'_0.m(e'_1, \ldots, e'_n) \rrbracket_{FV(e)}$.
  From induction hypothesis, for any $C[-]$, it holds that $C[e_i] \rightsquigarrow_\beta C[e'_i]$.
  Using compositionality, it also holds that for any $C[-]$, it is the case that
  $C[e_0.m(e_1, \ldots, e_n)] \rightsquigarrow_\beta C[e'_0.m(e'_1, \ldots, e'_n)]$.
  
\vspace{0.75em}\noindent(2) $\ident{bind}_{\Gamma, \Delta}(e_0.m(e_1, \ldots, e_n))$ --
  This case is similar to (1), except that the fact that $\bndclr{v} = \bnd{mem}(m, s)$
  holds by construction, rather than using Lemma~\ref{thm:lemma-lookup}.

\vspace{0.75em}\noindent(3) We assume that the expression $e$ does not include let bindings and
  so this case never happens.

\vspace{0.75em}\noindent(4) $\ident{bind}_{\Gamma, \Delta}(n)$ -- In this case $e=n$ and $\bndclr{v} = \bnd{val}(n)$. The preview of
  $\bnd{val}(n)$ is evaluated to $n$ using the (\emph{val}) case.

\vspace{0.75em}\noindent(5) $\ident{bind}_{\Gamma, \Delta}(x)$ -- The initial $\Gamma$ is empty and
  there are no let bindings, so $x$ must have been added to $\Gamma$ by case (6) or (7). Hence,
  $\bndclr{v}=\bnd{var}(x)$. Using (\emph{var}) $\bndclr{v}\Downarrow \llbracket x \rrbracket_{x}$
  and so $e_p = e = x$ and the second case (b.) trivially holds.  

\vspace{0.75em}\noindent(6) $\ident{bind}_{\Gamma, \Delta}(\lambda x\rightarrow e)$ -- Assume
  $\bndclr{v_b}$ is a graph node representing the body. The evaluation can use one of three rules: 
  
  If $FV(e)=\emptyset$ then $\bndclr{v_b}\Downarrow p_b$ for some $p_b$ and $\bndclr{v}\Downarrow \lambda x.p_b$ 
  using (\emph{fun-val}). From induction $e_b \rightsquigarrow_\beta p_b$
  and so by definition also $\lambda x.e_b \rightsquigarrow_\beta \lambda x.p_b$.

  If $FV(e)=\{x\}$ then $\bndclr{v_b}\Downarrow \llbracket e_b \rrbracket_x$ for some $e_b$ and
  $\bndclr{v}\Downarrow \lambda x.e_b$ using (\emph{fun-bind}). From 
  induction, for any context $C[-]$, it holds that $C[e] \rightsquigarrow_\beta C[e_b]$.
  Using a context $C[-]=\lambda x.-$ it holds that $\lambda x.e \rightsquigarrow_\beta \lambda x.e_b$.

  Otherwise, $\bndclr{v_b}\Downarrow \llbracket e_b \rrbracket_{x,\Gamma}$ for some $e_b$ and
  $\bndclr{v}\Downarrow \llbracket\lambda x.e_b\rrbracket_\Gamma$ using (\emph{fun-expr}). From
  induction, for any context $C[-]$, it holds that $C[e] \rightsquigarrow_\beta C[e_b]$ 
  and for any context $C'[-]$, by definition of $\rightsquigarrow_\beta$ also 
  $C'[\lambda x.e] \rightsquigarrow C'[\lambda x.e_b]$.
\end{proof}

\end{document}
